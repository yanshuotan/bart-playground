
# Draft file generated by LLM
# Not a unit test yet

import numpy as np
import sys
from os.path import abspath, dirname
# Add the parent directory (module) to the search path
sys.path.append(abspath(dirname(dirname(__file__))))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

# Assuming BCF class is implemented in bcf.py
from src.bcf import BCF

# 1. Generate Synthetic Data with Heterogeneous Treatment Effects
def generate_bcf_data(n=1000, p=10, noise_level=0.5, random_state=42):
    """Generate synthetic dataset with true treatment effects"""
    rng = np.random.default_rng(random_state)
    
    # Generate covariates
    X = rng.normal(0, 1, (n, p))
    
    # Generate prognostic effects (mu)
    mu = 2 * np.sin(np.pi * X[:,0]) + X[:,1]**2
    
    # Generate treatment effects (tau)
    tau = 0.5 * X[:,2] + 0.5 * (X[:,3] > 0)
    
    # Generate treatment assignment
    z = rng.binomial(1, 0.5, n)
    
    # Generate outcomes
    y = mu + z * tau + rng.normal(0, noise_level, n)
    
    return X, y, z, mu, tau

# Generate data
X, y, z, true_mu, true_tau = generate_bcf_data(n=2000)
X_train, X_test, y_train, y_test, z_train, z_test, mu_train, mu_test, tau_train, tau_test = \
    train_test_split(X, y, z, true_mu, true_tau, test_size=0.2, random_state=42)

# 2. Initialize and Fit BCF Model
bcf = BCF(
    n_mu_trees=200,       # Number of prognostic effect trees
    n_tau_trees=50,       # Number of treatment effect trees
    mu_alpha=0.95,        # Tree depth prior for mu
    mu_beta=2.0,          # Tree depth prior for mu
    tau_alpha=0.5,        # Simpler trees for treatment effects
    tau_beta=3.0,         # Penalize complex tau trees
    tau_k=0.5,            # Regularization for treatment effects
    ndpost=1000,          # Posterior samples
    nskip=100,            # Burn-in iterations
    random_state=42
)

# Fit the model (should take ~1-2 minutes for 2000 samples)
bcf.fit(X_train, y_train, z_train)

# 3. Predict on Test Set
post_mu, post_tau = bcf.predict_components(X_test)

# Calculate posterior means
mu_hat = post_mu.mean(axis=1)
tau_hat = post_tau.mean(axis=1)

# 4. Evaluate Performance
# Calculate RMSE for prognostic and treatment effects
mu_rmse = np.sqrt(np.mean((mu_hat - mu_test)**2))
tau_rmse = np.sqrt(np.mean((tau_hat - tau_test)**2))

print(f"Prognostic effect RMSE: {mu_rmse:.3f}")
print(f"Treatment effect RMSE: {tau_rmse:.3f}")

# 5. Visualize Results
plt.figure(figsize=(12, 5))

# Plot true vs estimated CATE
plt.subplot(1, 2, 1)
sns.scatterplot(x=tau_test, y=tau_hat, alpha=0.5)
plt.plot([-2, 2], [-2, 2], '--r')
plt.xlabel("True Treatment Effect")
plt.ylabel("Estimated Treatment Effect")
plt.title("CATE Estimation Accuracy")

# Plot posterior uncertainty
plt.subplot(1, 2, 2)
example_idx = np.argsort(tau_test)[::50]  # Select diverse examples
sns.boxplot(data=post_tau[example_idx].T, orient='h')
plt.yticks(np.arange(len(example_idx)), [f"Case {i+1}" for i in range(len(example_idx))])
plt.xlabel("Treatment Effect Posterior Distribution")
plt.title("Heterogeneous Treatment Effects");

# 6. Calculate Uncertainty Quantification
# Get 90% credible intervals
tau_lower = np.quantile(post_tau, 0.05, axis=1)
tau_upper = np.quantile(post_tau, 0.95, axis=1)

# Coverage probability
coverage = np.mean((tau_test >= tau_lower) & (tau_test <= tau_upper))
print(f"90% Credible Interval Coverage: {coverage:.2%}")

# 7. Feature Importance (Treatment Effect Drivers)
tau_feature_importance = np.abs(post_tau @ X_test).mean(axis=0)
plt.figure()
sns.barplot(x=tau_feature_importance, y=[f"X{i+1}" for i in range(X.shape[1])])
plt.title("Feature Importance for Treatment Effects")
