{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bart_playground import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook = \"real3_CalHousing_3tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.astype(float)\n",
    "y = np.array(y).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndpost = 50000\n",
    "nskip = 0\n",
    "n_trees = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Allocation failed (probably too large).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart-playground\\diagnosis\\experiment.py\", line 23, in run_experiment\n    bart_default.fit(X_train, y_train)\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart-playground\\bart_playground\\bart.py\", line 34, in fit\n    self.trace = self.sampler.run(self.ndpost + self.nskip, quietly=quietly, n_skip=self.nskip)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart-playground\\bart_playground\\samplers.py\", line 122, in run\n    current_state = self.one_iter(current_state, temp, return_trace=False)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart-playground\\bart_playground\\samplers.py\", line 305, in one_iter\n    if np.log(Z) < self.log_mh_ratio(move, temp, move_key=move_key, marginalize=marginalize):\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart-playground\\bart_playground\\samplers.py\", line 159, in log_mh_ratio\n    return (self.tree_prior.trees_log_prior_ratio(move) + \\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart-playground\\bart_playground\\priors.py\", line 222, in trees_log_prior_ratio\n    log_prior_current = self.trees_log_prior(move.current, move.trees_changed)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Learning\\Phd\\BART\\bartpy\\bart-playground\\bart_playground\\priors.py\", line 217, in trees_log_prior\n    log_prior += _trees_log_prior_numba(tree.vars, self.alpha, self.beta, self.quick_decay)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nMemoryError: Allocation failed (probably too large).\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexperiment\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_parallel_experiments\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Run 5 parallel experiments with different train-test splits\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_parallel_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndpost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnskip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnotebook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Learning\\Phd\\BART\\bartpy\\bart-playground\\diagnosis\\experiment.py:59\u001b[0m, in \u001b[0;36mrun_parallel_experiments\u001b[1;34m(X, y, ndpost, nskip, n_trees, notebook, m_tries, n_runs, n_jobs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_parallel_experiments\u001b[39m(X, y, ndpost, nskip, n_trees, notebook, m_tries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run parallel experiments with different train-test splits\"\"\"\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_experiment\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndpost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnskip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_tries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnotebook\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_runs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Learning\\Phd\\BART\\bartpy\\bart_env\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Allocation failed (probably too large)."
     ]
    }
   ],
   "source": [
    "from experiment import run_parallel_experiments\n",
    "\n",
    "# Run 5 parallel experiments with different train-test splits\n",
    "results = run_parallel_experiments(X, y, ndpost, nskip, n_trees, notebook, n_runs=5, n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default\n",
    "### KPSS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnosis import segmented_kpss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results and collect statistics\n",
    "n_runs = 5\n",
    "\n",
    "# Collect convergence statistics\n",
    "default_sigma_convergence = []\n",
    "default_rmse_convergence = []\n",
    "default_sigma_rates = []\n",
    "default_rmse_rates = []\n",
    "\n",
    "# Analyze Default BART results\n",
    "print(\"=== Default BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Load sigmas and rmses for this run\n",
    "    sigmas = np.load(f'store/{notebook}_sigmas_default_run{run_id}.npy')\n",
    "    rmses = np.load(f'store/{notebook}_rmses_default_run{run_id}.npy')\n",
    "    \n",
    "    print(f\"Sigma convergence analysis:\")\n",
    "    convergence_result = segmented_kpss_test(sigmas, segment_length=100)\n",
    "    print(f\"Chain converged: {convergence_result['converged']}\")\n",
    "    if convergence_result['converged']:\n",
    "        print(f\"Convergence at iteration: {convergence_result['convergence_iteration']}\")\n",
    "        default_sigma_convergence.append(convergence_result['convergence_iteration'])\n",
    "    print(f\"Convergence rate: {convergence_result['convergence_rate']:.2%}\")\n",
    "    default_sigma_rates.append(convergence_result['convergence_rate'])\n",
    "    \n",
    "    print(f\"\\nRMSE convergence analysis:\")\n",
    "    convergence_result = segmented_kpss_test(rmses, segment_length=100)\n",
    "    print(f\"Chain converged: {convergence_result['converged']}\")\n",
    "    if convergence_result['converged']:\n",
    "        print(f\"Convergence at iteration: {convergence_result['convergence_iteration']}\")\n",
    "        default_rmse_convergence.append(convergence_result['convergence_iteration'])\n",
    "    print(f\"Convergence rate: {convergence_result['convergence_rate']:.2%}\")\n",
    "    default_rmse_rates.append(convergence_result['convergence_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for Default BART\n",
    "print(\"\\n=== Default BART Summary ===\")\n",
    "if default_sigma_convergence:\n",
    "    print(f\"Sigma - Average convergence iteration: {np.mean(default_sigma_convergence):.0f}\")\n",
    "else:\n",
    "    print(\"Sigma - No convergence detected\")\n",
    "print(f\"Sigma - Average convergence rate: {np.mean(default_sigma_rates):.2%}\")\n",
    "\n",
    "if default_rmse_convergence:\n",
    "    print(f\"RMSE - Average convergence iteration: {np.mean(default_rmse_convergence):.0f}\")\n",
    "else:\n",
    "    print(\"RMSE - No convergence detected\")\n",
    "print(f\"RMSE - Average convergence rate: {np.mean(default_rmse_rates):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add logging configuration before importing arviz\n",
    "import logging\n",
    "logging.getLogger('arviz.preview').setLevel(logging.WARNING)\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results\n",
    "n_runs = 5\n",
    "\n",
    "# Analyze Default BART results\n",
    "print(\"=== Default BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Load sigmas and rmses for this run\n",
    "    sigmas = np.load(f'store/{notebook}_sigmas_default_run{run_id}.npy')\n",
    "    rmses = np.load(f'store/{notebook}_rmses_default_run{run_id}.npy')\n",
    "\n",
    "    print(f\"Sigma ess value: {az.ess(sigmas[10000:].reshape(1, -1), relative=True).item():.6f}\")\n",
    "    print(f\"RMSE ess value: {az.ess(rmses[10000:].reshape(1, -1), relative=True).item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnosis import plot_autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results\n",
    "n_runs = 5\n",
    "\n",
    "# Analyze Default BART results\n",
    "print(\"=== Default BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Load sigmas and rmses for this run\n",
    "    sigmas = np.load(f'store/{notebook}_sigmas_default_run{run_id}.npy')\n",
    "    rmses = np.load(f'store/{notebook}_rmses_default_run{run_id}.npy')\n",
    "\n",
    "    print(f\"Sigma autocorrelation plot:\")\n",
    "    plot_autocorrelation(sigmas[10000:], nlags=500)\n",
    "    \n",
    "    print(f\"RMSE autocorrelation plot:\")\n",
    "    plot_autocorrelation(rmses[10000:], nlags=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTMH\n",
    "### KPSS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnosis import segmented_kpss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results and collect statistics\n",
    "n_runs = 5\n",
    "\n",
    "# Collect convergence statistics\n",
    "mtmh_sigma_convergence = []\n",
    "mtmh_rmse_convergence = []\n",
    "mtmh_sigma_rates = []\n",
    "mtmh_rmse_rates = []\n",
    "\n",
    "# Analyze MTMH BART results\n",
    "print(\"=== MTMH BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Load sigmas and rmses for this run\n",
    "    sigmas = np.load(f'store/{notebook}_sigmas_mtmh_run{run_id}.npy')\n",
    "    rmses = np.load(f'store/{notebook}_rmses_mtmh_run{run_id}.npy')\n",
    "\n",
    "    print(f\"Sigma convergence analysis:\")\n",
    "    convergence_result = segmented_kpss_test(sigmas, segment_length=100)\n",
    "    print(f\"Chain converged: {convergence_result['converged']}\")\n",
    "    if convergence_result['converged']:\n",
    "        print(f\"Convergence at iteration: {convergence_result['convergence_iteration']}\")\n",
    "        mtmh_sigma_convergence.append(convergence_result['convergence_iteration'])\n",
    "    print(f\"Convergence rate: {convergence_result['convergence_rate']:.2%}\")\n",
    "    mtmh_sigma_rates.append(convergence_result['convergence_rate'])\n",
    "\n",
    "    print(f\"\\nRMSE convergence analysis:\")\n",
    "    convergence_result = segmented_kpss_test(rmses, segment_length=100)\n",
    "    print(f\"Chain converged: {convergence_result['converged']}\")\n",
    "    if convergence_result['converged']:\n",
    "        print(f\"Convergence at iteration: {convergence_result['convergence_iteration']}\")\n",
    "        mtmh_rmse_convergence.append(convergence_result['convergence_iteration'])\n",
    "    print(f\"Convergence rate: {convergence_result['convergence_rate']:.2%}\")\n",
    "    mtmh_rmse_rates.append(convergence_result['convergence_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for MTMH BART\n",
    "print(\"\\n=== MTMH BART Summary ===\")\n",
    "if mtmh_sigma_convergence:\n",
    "    print(f\"Sigma - Average convergence iteration: {np.mean(mtmh_sigma_convergence):.0f}\")\n",
    "else:\n",
    "    print(\"Sigma - No convergence detected\")\n",
    "print(f\"Sigma - Average convergence rate: {np.mean(mtmh_sigma_rates):.2%}\")\n",
    "\n",
    "if mtmh_rmse_convergence:\n",
    "    print(f\"RMSE - Average convergence iteration: {np.mean(mtmh_rmse_convergence):.0f}\")\n",
    "else:\n",
    "    print(\"RMSE - No convergence detected\")\n",
    "print(f\"RMSE - Average convergence rate: {np.mean(mtmh_rmse_rates):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add logging configuration before importing arviz\n",
    "import logging\n",
    "logging.getLogger('arviz.preview').setLevel(logging.WARNING)\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results\n",
    "n_runs = 5\n",
    "\n",
    "# Analyze MTMH BART results\n",
    "print(\"=== MTMH BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Load sigmas and rmses for this run\n",
    "    sigmas = np.load(f'store/{notebook}_sigmas_mtmh_run{run_id}.npy')\n",
    "    rmses = np.load(f'store/{notebook}_rmses_mtmh_run{run_id}.npy')\n",
    "\n",
    "    print(f\"Sigma ess value: {az.ess(sigmas[10000:].reshape(1, -1), relative=True).item():.6f}\")\n",
    "    print(f\"RMSE ess value: {az.ess(rmses[10000:].reshape(1, -1), relative=True).item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnosis import plot_autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results\n",
    "n_runs = 5\n",
    "\n",
    "# Analyze MTMH BART results\n",
    "print(\"=== MTMH BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Load sigmas and rmses for this run\n",
    "    sigmas = np.load(f'store/{notebook}_sigmas_mtmh_run{run_id}.npy')\n",
    "    rmses = np.load(f'store/{notebook}_rmses_mtmh_run{run_id}.npy')\n",
    "\n",
    "    print(f\"Sigma autocorrelation plot:\")\n",
    "    plot_autocorrelation(sigmas[10000:], nlags=500)\n",
    "    \n",
    "    print(f\"RMSE autocorrelation plot:\")\n",
    "    plot_autocorrelation(rmses[10000:], nlags=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bart_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
