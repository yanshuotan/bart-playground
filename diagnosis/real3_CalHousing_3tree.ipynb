{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bart_playground import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook = \"real3_CalHousing_3tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.astype(float)\n",
    "y = np.array(y).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndpost = 10000\n",
    "nskip = 0\n",
    "n_trees = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 95 concurrent workers.\n",
      "Iterations: 100%|██████████| 10000/10000 [00:30<00:00, 324.81it/s]\n",
      "Iterations: 100%|██████████| 10000/10000 [00:36<00:00, 272.58it/s]\n",
      "Iterations: 100%|██████████| 10000/10000 [00:50<00:00, 197.17it/s]\n",
      "Iterations: 100%|██████████| 10000/10000 [01:40<00:00, 99.37it/s]\n",
      "Iterations:  75%|███████▌  | 7535/10000 [06:02<01:14, 33.08it/s]   "
     ]
    }
   ],
   "source": [
    "from experiment import run_parallel_experiments\n",
    "\n",
    "# Run 5 parallel experiments\n",
    "results = run_parallel_experiments(X, y, ndpost, nskip, n_trees, notebook, n_runs=5, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = np.load(f'store/{notebook}.npz', allow_pickle=True)\n",
    "\n",
    "default_data = experiment_results['default'].item()\n",
    "mtmh_data = experiment_results['mtmh'].item()\n",
    "metadata = experiment_results['metadata'].item()\n",
    "\n",
    "n_runs = metadata['n_runs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace Plots Analysis\n",
    "## Tree Depth / #Leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract leaves and depths data for visualization\n",
    "n_runs = experiment_results['metadata'].item()['n_runs']\n",
    "\n",
    "fig, axes = plt.subplots(n_runs, 2, figsize=(15, 4*n_runs))\n",
    "if n_runs == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    # Extract data for this run\n",
    "    default_leaves = experiment_results['default'].item()['leaves'][run_id]\n",
    "    mtmh_leaves = experiment_results['mtmh'].item()['leaves'][run_id]\n",
    "    default_depths = experiment_results['default'].item()['depths'][run_id]\n",
    "    mtmh_depths = experiment_results['mtmh'].item()['depths'][run_id]\n",
    "    \n",
    "    # Plot leaves (left column)\n",
    "    axes[run_id, 0].plot(default_leaves, label='Default BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 0].plot(mtmh_leaves, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 0].set_title(f'Run {run_id} - Average Leaves per Tree')\n",
    "    axes[run_id, 0].set_xlabel('Iteration')\n",
    "    axes[run_id, 0].set_ylabel('Average Leaves')\n",
    "    axes[run_id, 0].legend()\n",
    "    axes[run_id, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot depths (right column)\n",
    "    axes[run_id, 1].plot(default_depths, label='Default BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 1].plot(mtmh_depths, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 1].set_title(f'Run {run_id} - Average Tree Depth')\n",
    "    axes[run_id, 1].set_xlabel('Iteration')\n",
    "    axes[run_id, 1].set_ylabel('Average Depth')\n",
    "    axes[run_id, 1].legend()\n",
    "    axes[run_id, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract data across all runs\n",
    "n_runs = experiment_results['metadata'].item()['n_runs']\n",
    "\n",
    "# Collect all runs data\n",
    "default_leaves_all = []\n",
    "mtmh_leaves_all = []\n",
    "default_depths_all = []\n",
    "mtmh_depths_all = []\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    default_leaves_all.append(experiment_results['default'].item()['leaves'][run_id])\n",
    "    mtmh_leaves_all.append(experiment_results['mtmh'].item()['leaves'][run_id])\n",
    "    default_depths_all.append(experiment_results['default'].item()['depths'][run_id])\n",
    "    mtmh_depths_all.append(experiment_results['mtmh'].item()['depths'][run_id])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "default_leaves_all = np.array(default_leaves_all)  # Shape: (n_runs, n_iterations)\n",
    "mtmh_leaves_all = np.array(mtmh_leaves_all)\n",
    "default_depths_all = np.array(default_depths_all)\n",
    "mtmh_depths_all = np.array(mtmh_depths_all)\n",
    "\n",
    "# Calculate mean and std across runs\n",
    "default_leaves_mean = np.mean(default_leaves_all, axis=0)\n",
    "mtmh_leaves_mean = np.mean(mtmh_leaves_all, axis=0)\n",
    "\n",
    "default_depths_mean = np.mean(default_depths_all, axis=0)\n",
    "mtmh_depths_mean = np.mean(mtmh_depths_all, axis=0)\n",
    "\n",
    "# Create iteration axis\n",
    "iterations = np.arange(len(default_leaves_mean))\n",
    "\n",
    "# Plot averaged results with error bands\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot leaves\n",
    "ax1.plot(iterations, default_leaves_mean, label='Default BART', alpha=0.7, linewidth=1)\n",
    "ax1.plot(iterations, mtmh_leaves_mean, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "ax1.set_title(f'Average Leaves per Tree (across {n_runs} runs)')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Average Leaves')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot depths\n",
    "ax2.plot(iterations, default_depths_mean, label='Default BART', alpha=0.7, linewidth=1)\n",
    "ax2.plot(iterations, mtmh_depths_mean, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "ax2.set_title(f'Average Tree Depth (across {n_runs} runs)')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Average Depth')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmas & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract sigmas and rmses data for visualization\n",
    "n_runs = experiment_results['metadata'].item()['n_runs']\n",
    "\n",
    "fig, axes = plt.subplots(n_runs, 2, figsize=(15, 4*n_runs))\n",
    "if n_runs == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    # Extract data for this run\n",
    "    default_sigmas = experiment_results['default'].item()['sigmas'][run_id]\n",
    "    mtmh_sigmas = experiment_results['mtmh'].item()['sigmas'][run_id]\n",
    "    default_rmses = experiment_results['default'].item()['rmses'][run_id]\n",
    "    mtmh_rmses = experiment_results['mtmh'].item()['rmses'][run_id]\n",
    "\n",
    "    # Plot sigmas (left column)\n",
    "    axes[run_id, 0].plot(default_sigmas, label='Default BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 0].plot(mtmh_sigmas, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 0].set_title(f'Run {run_id} - Sigmas')\n",
    "    axes[run_id, 0].set_xlabel('Iteration')\n",
    "    axes[run_id, 0].set_ylabel('Sigmas')\n",
    "    axes[run_id, 0].legend()\n",
    "    axes[run_id, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot rmses (right column)\n",
    "    axes[run_id, 1].plot(default_rmses, label='Default BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 1].plot(mtmh_rmses, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 1].set_title(f'Run {run_id} - RMSEs')\n",
    "    axes[run_id, 1].set_xlabel('Iteration')\n",
    "    axes[run_id, 1].set_ylabel('RMSE')\n",
    "    axes[run_id, 1].legend()\n",
    "    axes[run_id, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract sigmas and rmses data for visualization\n",
    "n_runs = experiment_results['metadata'].item()['n_runs']\n",
    "\n",
    "fig, axes = plt.subplots(n_runs, 2, figsize=(15, 4*n_runs))\n",
    "if n_runs == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    # Extract data for this run\n",
    "    default_sigmas = experiment_results['default'].item()['sigmas'][run_id]\n",
    "    mtmh_sigmas = experiment_results['mtmh'].item()['sigmas'][run_id]\n",
    "    default_rmses = experiment_results['default'].item()['rmses'][run_id]\n",
    "    mtmh_rmses = experiment_results['mtmh'].item()['rmses'][run_id]\n",
    "\n",
    "    # Plot sigmas (left column)\n",
    "    axes[run_id, 0].plot(default_sigmas[3000:], label='Default BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 0].plot(mtmh_sigmas[3000:], label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 0].set_title(f'Run {run_id} - Sigmas')\n",
    "    axes[run_id, 0].set_xlabel('Iteration')\n",
    "    axes[run_id, 0].set_ylabel('Sigmas')\n",
    "    axes[run_id, 0].legend()\n",
    "    axes[run_id, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot rmses (right column)\n",
    "    axes[run_id, 1].plot(default_rmses[3000:], label='Default BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 1].plot(mtmh_rmses[3000:], label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "    axes[run_id, 1].set_title(f'Run {run_id} - RMSEs')\n",
    "    axes[run_id, 1].set_xlabel('Iteration')\n",
    "    axes[run_id, 1].set_ylabel('RMSE')\n",
    "    axes[run_id, 1].legend()\n",
    "    axes[run_id, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract data across all runs\n",
    "n_runs = experiment_results['metadata'].item()['n_runs']\n",
    "\n",
    "# Collect all runs data\n",
    "default_sigmas_all = []\n",
    "mtmh_sigmas_all = []\n",
    "default_rmses_all = []\n",
    "mtmh_rmses_all = []\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    default_sigmas_all.append(experiment_results['default'].item()['sigmas'][run_id])\n",
    "    mtmh_sigmas_all.append(experiment_results['mtmh'].item()['sigmas'][run_id])\n",
    "    default_rmses_all.append(experiment_results['default'].item()['rmses'][run_id])\n",
    "    mtmh_rmses_all.append(experiment_results['mtmh'].item()['rmses'][run_id])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "default_sigmas_all = np.array(default_sigmas_all)  # Shape: (n_runs, n_iterations)\n",
    "mtmh_sigmas_all = np.array(mtmh_sigmas_all)\n",
    "default_rmses_all = np.array(default_rmses_all)\n",
    "mtmh_rmses_all = np.array(mtmh_rmses_all)\n",
    "\n",
    "# Calculate mean and std across runs\n",
    "default_sigmas_mean = np.mean(default_sigmas_all, axis=0)\n",
    "mtmh_sigmas_mean = np.mean(mtmh_sigmas_all, axis=0)\n",
    "\n",
    "default_rmses_mean = np.mean(default_rmses_all, axis=0)\n",
    "mtmh_rmses_mean = np.mean(mtmh_rmses_all, axis=0)\n",
    "\n",
    "# Plot averaged results with error bands\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot sigmas\n",
    "iterations = np.arange(len(default_sigmas_mean))\n",
    "ax1.plot(iterations, default_sigmas_mean, label='Default BART', alpha=0.7, linewidth=1)\n",
    "ax1.plot(iterations, mtmh_sigmas_mean, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "ax1.set_title(f'Sigmas (across {n_runs} runs)')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Sigmas')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot rmses\n",
    "iterations = np.arange(len(default_rmses_mean))\n",
    "ax2.plot(iterations, default_rmses_mean, label='Default BART', alpha=0.7, linewidth=1)\n",
    "ax2.plot(iterations, mtmh_rmses_mean, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "ax2.set_title(f'RMSE (across {n_runs} runs)')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data after burn-in\n",
    "default_sigmas_mean = default_sigmas_mean[3000:]\n",
    "mtmh_sigmas_mean = mtmh_sigmas_mean[3000:]\n",
    "\n",
    "default_rmses_mean = default_rmses_mean[3000:]\n",
    "mtmh_rmses_mean = mtmh_rmses_mean[3000:]\n",
    "\n",
    "# Plot averaged results with error bands\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot sigmas\n",
    "iterations = np.arange(len(default_sigmas_mean))\n",
    "ax1.plot(iterations, default_sigmas_mean, label='Default BART', alpha=0.7, linewidth=1)\n",
    "ax1.plot(iterations, mtmh_sigmas_mean, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "ax1.set_title(f'Sigmas (across {n_runs} runs)')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Sigmas')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot rmses\n",
    "iterations = np.arange(len(default_rmses_mean))\n",
    "ax2.plot(iterations, default_rmses_mean, label='Default BART', alpha=0.7, linewidth=1)\n",
    "ax2.plot(iterations, mtmh_rmses_mean, label='MTMH BART', alpha=0.7, linewidth=1)\n",
    "ax2.set_title(f'RMSE (across {n_runs} runs)')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence Analysis\n",
    "## KPSS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnosis import segmented_kpss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results and collect statistics\n",
    "n_runs = experiment_results['metadata'].item()['n_runs']\n",
    "\n",
    "# Collect convergence statistics\n",
    "default_sigma_convergence = []\n",
    "default_rmse_convergence = []\n",
    "default_sigma_rates = []\n",
    "default_rmse_rates = []\n",
    "\n",
    "# Analyze Default BART results\n",
    "print(\"=== Default BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Default Run {run_id} ---\")\n",
    "    \n",
    "    # Extract data for this run from the combined arrays\n",
    "    sigmas = experiment_results['default'].item()['sigmas'][run_id]\n",
    "    rmses = experiment_results['default'].item()['rmses'][run_id]\n",
    "    \n",
    "    print(f\"Sigma convergence analysis:\")\n",
    "    convergence_result = segmented_kpss_test(sigmas, segment_length=100)\n",
    "    print(f\"Default Chain converged: {convergence_result['converged']}\")\n",
    "    if convergence_result['converged']:\n",
    "        print(f\"Convergence at iteration: {convergence_result['convergence_iteration']}\")\n",
    "        default_sigma_convergence.append(convergence_result['convergence_iteration'])\n",
    "    print(f\"Convergence rate: {convergence_result['convergence_rate']:.2%}\")\n",
    "    default_sigma_rates.append(convergence_result['convergence_rate'])\n",
    "    \n",
    "    print(f\"\\nRMSE convergence analysis:\")\n",
    "    convergence_result = segmented_kpss_test(rmses, segment_length=100)\n",
    "    print(f\"Default Chain converged: {convergence_result['converged']}\")\n",
    "    if convergence_result['converged']:\n",
    "        print(f\"Convergence at iteration: {convergence_result['convergence_iteration']}\")\n",
    "        default_rmse_convergence.append(convergence_result['convergence_iteration'])\n",
    "    print(f\"Convergence rate: {convergence_result['convergence_rate']:.2%}\")\n",
    "    default_rmse_rates.append(convergence_result['convergence_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results and collect statistics\n",
    "n_runs = 5\n",
    "\n",
    "# Collect convergence statistics\n",
    "mtmh_sigma_convergence = []\n",
    "mtmh_rmse_convergence = []\n",
    "mtmh_sigma_rates = []\n",
    "mtmh_rmse_rates = []\n",
    "\n",
    "# Analyze MTMH BART results\n",
    "print(\"=== MTMH BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- MTMH Run {run_id} ---\")\n",
    "    \n",
    "    # Extract data for this run from the combined arrays\n",
    "    sigmas = experiment_results['mtmh'].item()['sigmas'][run_id]\n",
    "    rmses = experiment_results['mtmh'].item()['rmses'][run_id]\n",
    "\n",
    "    print(f\"Sigma convergence analysis:\")\n",
    "    convergence_result = segmented_kpss_test(sigmas, segment_length=100)\n",
    "    print(f\"MTMH Chain converged: {convergence_result['converged']}\")\n",
    "    if convergence_result['converged']:\n",
    "        print(f\"Convergence at iteration: {convergence_result['convergence_iteration']}\")\n",
    "        mtmh_sigma_convergence.append(convergence_result['convergence_iteration'])\n",
    "    print(f\"Convergence rate: {convergence_result['convergence_rate']:.2%}\")\n",
    "    mtmh_sigma_rates.append(convergence_result['convergence_rate'])\n",
    "\n",
    "    print(f\"\\nRMSE convergence analysis:\")\n",
    "    convergence_result = segmented_kpss_test(rmses, segment_length=100)\n",
    "    print(f\"MTMH Chain converged: {convergence_result['converged']}\")\n",
    "    if convergence_result['converged']:\n",
    "        print(f\"Convergence at iteration: {convergence_result['convergence_iteration']}\")\n",
    "        mtmh_rmse_convergence.append(convergence_result['convergence_iteration'])\n",
    "    print(f\"Convergence rate: {convergence_result['convergence_rate']:.2%}\")\n",
    "    mtmh_rmse_rates.append(convergence_result['convergence_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for Default BART\n",
    "print(\"\\n=== Default BART Summary ===\")\n",
    "if default_sigma_convergence:\n",
    "    print(f\"Sigma - Average convergence iteration: {np.mean(default_sigma_convergence):.0f}\")\n",
    "else:\n",
    "    print(\"Sigma - No convergence detected\")\n",
    "print(f\"Sigma - Average convergence rate: {np.mean(default_sigma_rates):.2%}\")\n",
    "\n",
    "if default_rmse_convergence:\n",
    "    print(f\"RMSE - Average convergence iteration: {np.mean(default_rmse_convergence):.0f}\")\n",
    "else:\n",
    "    print(\"RMSE - No convergence detected\")\n",
    "print(f\"RMSE - Average convergence rate: {np.mean(default_rmse_rates):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for MTMH BART\n",
    "print(\"\\n=== MTMH BART Summary ===\")\n",
    "if mtmh_sigma_convergence:\n",
    "    print(f\"Sigma - Average convergence iteration: {np.mean(mtmh_sigma_convergence):.0f}\")\n",
    "else:\n",
    "    print(\"Sigma - No convergence detected\")\n",
    "print(f\"Sigma - Average convergence rate: {np.mean(mtmh_sigma_rates):.2%}\")\n",
    "\n",
    "if mtmh_rmse_convergence:\n",
    "    print(f\"RMSE - Average convergence iteration: {np.mean(mtmh_rmse_convergence):.0f}\")\n",
    "else:\n",
    "    print(\"RMSE - No convergence detected\")\n",
    "print(f\"RMSE - Average convergence rate: {np.mean(mtmh_rmse_rates):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add logging configuration before importing arviz\n",
    "import logging\n",
    "logging.getLogger('arviz.preview').setLevel(logging.WARNING)\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract prediction data for ESS analysis\n",
    "n_runs = experiment_results['metadata'].item()['n_runs']\n",
    "\n",
    "# Collect ESS values for each test data point across all runs\n",
    "default_ess_per_point = []\n",
    "mtmh_ess_per_point = []\n",
    "\n",
    "print(\"=== Prediction ESS Analysis ===\")\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Extract prediction data for this run (shape: n_test_samples x n_iterations)\n",
    "    default_preds = experiment_results['default'].item()['preds'][run_id]\n",
    "    mtmh_preds = experiment_results['mtmh'].item()['preds'][run_id]\n",
    "    \n",
    "    # Remove burn-in period (first 3000 iterations)\n",
    "    default_preds_burnin = default_preds[:, 3000:]  # Shape: n_test_samples x (n_iterations - 3000)\n",
    "    mtmh_preds_burnin = mtmh_preds[:, 3000:]\n",
    "    \n",
    "    # Calculate ESS for each test data point\n",
    "    default_ess_run = []\n",
    "    mtmh_ess_run = []\n",
    "    \n",
    "    n_test_samples = default_preds_burnin.shape[0]\n",
    "    \n",
    "    for i in range(n_test_samples):\n",
    "        # ESS for each test point's prediction trace\n",
    "        default_ess = az.ess(default_preds_burnin[i].reshape(1, -1), relative=True).item()\n",
    "        mtmh_ess = az.ess(mtmh_preds_burnin[i].reshape(1, -1), relative=True).item()\n",
    "        \n",
    "        default_ess_run.append(default_ess)\n",
    "        mtmh_ess_run.append(mtmh_ess)\n",
    "    \n",
    "    default_ess_per_point.append(default_ess_run)\n",
    "    mtmh_ess_per_point.append(mtmh_ess_run)\n",
    "    \n",
    "    print(f\"Default BART - Mean ESS: {np.mean(default_ess_run):.4f}, Std ESS: {np.std(default_ess_run):.4f}\")\n",
    "    print(f\"MTMH BART - Mean ESS: {np.mean(mtmh_ess_run):.4f}, Std ESS: {np.std(mtmh_ess_run):.4f}\")\n",
    "\n",
    "# Convert to numpy arrays for easier manipulation\n",
    "default_ess_per_point = np.array(default_ess_per_point)  # Shape: (n_runs, n_test_samples)\n",
    "mtmh_ess_per_point = np.array(mtmh_ess_per_point)\n",
    "\n",
    "print(f\"\\nOverall across all runs:\")\n",
    "print(f\"Default BART - Mean ESS: {np.mean(default_ess_per_point):.4f}, Std ESS: {np.std(default_ess_per_point):.4f}\")\n",
    "print(f\"MTMH BART - Mean ESS: {np.mean(mtmh_ess_per_point):.4f}, Std ESS: {np.std(mtmh_ess_per_point):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ESS comparison for each test data point using scatter plots\n",
    "fig, axes = plt.subplots(n_runs, 1, figsize=(15, 4*n_runs))\n",
    "if n_runs == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    x = np.arange(len(default_ess_per_point[run_id]))\n",
    "    \n",
    "    axes[run_id].scatter(x, default_ess_per_point[run_id], \n",
    "                        label='Default BART', alpha=0.7, s=10)\n",
    "    axes[run_id].scatter(x, mtmh_ess_per_point[run_id], \n",
    "                        label='MTMH BART', alpha=0.7, s=10)\n",
    "\n",
    "    axes[run_id].set_title(f'Run {run_id} - ESS per Test Data Point')\n",
    "    axes[run_id].set_xlabel('Test Data Point Index')\n",
    "    axes[run_id].set_ylabel('ESS (Relative)')\n",
    "    axes[run_id].legend()\n",
    "    axes[run_id].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot averaged ESS across all runs (simplified without error bars)\n",
    "mean_default_ess = np.mean(default_ess_per_point, axis=0)\n",
    "mean_mtmh_ess = np.mean(mtmh_ess_per_point, axis=0)\n",
    "\n",
    "x = np.arange(len(mean_default_ess))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "\n",
    "ax.scatter(x, mean_default_ess, label='Default BART', alpha=0.7, s=10)\n",
    "ax.scatter(x, mean_mtmh_ess, label='MTMH BART', alpha=0.7, s=10)\n",
    "\n",
    "ax.set_title(f'Average ESS per Test Data Point (across {n_runs} runs)')\n",
    "ax.set_xlabel('Test Data Point Index')\n",
    "ax.set_ylabel('ESS (Relative)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(f\"Default BART - Average ESS across all points and runs: {np.mean(default_ess_per_point):.4f}\")\n",
    "print(f\"MTMH BART - Average ESS across all points and runs: {np.mean(mtmh_ess_per_point):.4f}\")\n",
    "print(f\"Improvement ratio (MTMH/Default): {np.mean(mtmh_ess_per_point)/np.mean(default_ess_per_point):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram comparison of ESS values\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Flatten all ESS values for histogram\n",
    "default_ess_flat = default_ess_per_point.flatten()\n",
    "mtmh_ess_flat = mtmh_ess_per_point.flatten()\n",
    "\n",
    "# Histogram for Default BART\n",
    "ax1.hist(default_ess_flat, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax1.set_title('Default BART - ESS Distribution')\n",
    "ax1.set_xlabel('ESS (Relative)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.axvline(np.mean(default_ess_flat), color='red', linestyle='--', \n",
    "            label=f'Mean: {np.mean(default_ess_flat):.4f}')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram for MTMH BART\n",
    "ax2.hist(mtmh_ess_flat, bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
    "ax2.set_title('MTMH BART - ESS Distribution')\n",
    "ax2.set_xlabel('ESS (Relative)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.axvline(np.mean(mtmh_ess_flat), color='red', linestyle='--', \n",
    "            label=f'Mean: {np.mean(mtmh_ess_flat):.4f}')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigma & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results\n",
    "n_runs = experiment_results['metadata'].item()['n_runs']\n",
    "\n",
    "# Analyze Default BART results\n",
    "print(\"=== Default BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Extract data for this run\n",
    "    sigmas = experiment_results['default'].item()['sigmas'][run_id]\n",
    "    rmses = experiment_results['default'].item()['rmses'][run_id]\n",
    "\n",
    "    print(f\"Sigma ess value: {az.ess(sigmas[3000:].reshape(1, -1), relative=True).item():.6f}\")\n",
    "    print(f\"RMSE ess value: {az.ess(rmses[3000:].reshape(1, -1), relative=True).item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results\n",
    "n_runs = 5\n",
    "\n",
    "# Analyze MTMH BART results\n",
    "print(\"=== MTMH BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Extract data for this run from the combined arrays\n",
    "    sigmas = experiment_results['mtmh'].item()['sigmas'][run_id]\n",
    "    rmses = experiment_results['mtmh'].item()['rmses'][run_id]\n",
    "\n",
    "    print(f\"Sigma ess value: {az.ess(sigmas[3000:].reshape(1, -1), relative=True).item():.6f}\")\n",
    "    print(f\"RMSE ess value: {az.ess(rmses[3000:].reshape(1, -1), relative=True).item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnosis import plot_autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results\n",
    "n_runs = 5\n",
    "\n",
    "# Analyze Default BART results\n",
    "print(\"=== Default BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Extract data for this run\n",
    "    sigmas = experiment_results['default'].item()['sigmas'][run_id]\n",
    "    rmses = experiment_results['default'].item()['rmses'][run_id]\n",
    "\n",
    "    print(f\"Default Sigma autocorrelation plot:\")\n",
    "    plot_autocorrelation(sigmas[3000:], nlags=500)\n",
    "\n",
    "    print(f\"Default RMSE autocorrelation plot:\")\n",
    "    plot_autocorrelation(rmses[3000:], nlags=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each run's results\n",
    "n_runs = 5\n",
    "\n",
    "# Analyze MTMH BART results\n",
    "print(\"=== MTMH BART Analysis ===\")\n",
    "for run_id in range(n_runs):\n",
    "    print(f\"\\n--- Run {run_id} ---\")\n",
    "    \n",
    "    # Extract data for this run from the combined arrays\n",
    "    sigmas = experiment_results['mtmh'].item()['sigmas'][run_id]\n",
    "    rmses = experiment_results['mtmh'].item()['rmses'][run_id]\n",
    "\n",
    "    print(f\"MTMH Sigma autocorrelation plot:\")\n",
    "    plot_autocorrelation(sigmas[3000:], nlags=500)\n",
    "\n",
    "    print(f\"MTMH RMSE autocorrelation plot:\")\n",
    "    plot_autocorrelation(rmses[3000:], nlags=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
