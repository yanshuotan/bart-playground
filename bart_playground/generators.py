
import numpy as np
import math
from bart_playground.params import Tree
from bart_playground.util import DefaultPreprocessor, fast_choice
from bart_playground.priors import TreesPrior
from scipy.stats import invgamma

def generate_X_grid(n, p, random_state: int | None = 42, dim_bins = None):
    rng = np.random.default_rng(random_state)
    dim_bins = math.ceil(n ** (1.0 / p)) if dim_bins is None else dim_bins
    bins = [np.linspace(0.0, 1.0, dim_bins, dtype=np.float32) for _ in range(p)]
    mesh = np.meshgrid(*bins, indexing='ij')
    grid = np.stack([m.ravel() for m in mesh], axis=-1)
    grid = rng.choice(grid, size=n, replace=False, axis=0)
    return grid

def generate_defaultbart_prior_with_cov(n, p, random_state: int | None = 42, dim_bins = None, **kwargs):
    return generate_data_from_defaultbart_prior(
        X=generate_X_grid(n, p, random_state, dim_bins),
        random_state=random_state,
        **kwargs
    )
        
def generate_data_from_defaultbart_prior(
    X: np.ndarray,
    *,
    n_trees: int = 200,
    tree_alpha: float = 0.95,
    tree_beta: float = 2.0,
    f_k: float = 2.0,
    eps_nu: float = 3.0,
    eps_lambda: float = 1.0,
    eps_sigma2: float | None = None,
    random_state: int | None = 42,
    max_depth: int = 10,
    min_node_size: int = 1,
    quick_decay: bool = False,
    max_bins: int = 100,
    return_latent: bool = False,
):
    """
    Generate regression data according to the DefaultBART prior.

    Generation process (prior predictive distribution):
    - For each tree, recursively sample the tree structure according to the prior p(split|depth)=alpha/(1+depth)^beta (quick_decay=False);
      variables are chosen uniformly, thresholds are sampled from the candidate set generated by the preprocessor; leaf values are drawn from N(0, f_sigma2), where f_sigma2=0.25/(f_k^2*n_trees)
    - f(x) is the sum of outputs from all trees
    - Noise variance sigma^2 ~ InvGamma(eps_nu/2, scale=eps_nu*eps_lambda/2), y = f(x) + eps

    Parameter notes:
    - eps_lambda is the noise prior scale (cannot be adaptively calibrated without data, must be set manually; default is 1.0)
    - max_depth/min_node_size limit the size of generated trees to avoid degenerate splits

    Returns:
    - (X, y); if return_latent=True, returns (X, y, f, sigma2, trees)
    """
    # Get dimensions and RNG
    n = X.shape[0]
    p = X.shape[1]
    rng = np.random.default_rng(random_state)

    # Candidate thresholds via DefaultPreprocessor (same mechanism DefaultBART uses)
    preprocessor = DefaultPreprocessor(max_bins=max_bins)
    thresholds_by_var = preprocessor.gen_thresholds(X)

    # Prior container for consistency with DefaultBART (for f_sigma2)
    tree_prior = TreesPrior(n_trees=n_trees, tree_alpha=tree_alpha, tree_beta=tree_beta, f_k=f_k, generator=rng, quick_decay=quick_decay)

    def p_split(depth: int) -> float:
        if quick_decay:
            return float(np.clip(tree_alpha ** depth, 0.0, 1.0))
        return float(np.clip(tree_alpha / ((1.0 + depth) ** tree_beta), 0.0, 1.0))

    def sample_tree_outputs_one_tree() -> tuple[np.ndarray, Tree]:
        # Start with a stump bound to X so internal counts/caches update on splits
        t = Tree.new(dataX=X)

        # Maintain a queue of (node_id, depth) for leaf nodes to consider splitting
        queue = [(0, 0)]
        while queue:
            node_id, depth = queue.pop()
            # Only attempt split if still a leaf and under constraints
            if depth >= max_depth:
                continue
            if t.vars[node_id] != -1:
                continue  # already split

            # Split decision under prior
            if rng.uniform() > p_split(depth):
                continue

            # Try a few times to find a valid (var, threshold) that yields non-empty children
            success = False
            for _ in range(32):
                var = int(fast_choice(rng, np.arange(p)))
                cands = thresholds_by_var[var]
                if cands.size == 0:
                    continue
                thr = fast_choice(rng, cands)
                is_valid = t.split_leaf(node_id=node_id, var=var, threshold=thr)
                if is_valid and (t.n[node_id * 2 + 1] >= min_node_size) and (t.n[node_id * 2 + 2] >= min_node_size):
                    success = True
                    break
                # revert failed split (prune back if created) â€“ if invalid, the helper didn't finalize counts,
                # but to be safe, ensure node remains a leaf by pruning.
                if t.vars[node_id] != -1:
                    try:
                        t.prune_split(node_id)
                    except Exception:
                        pass
            if not success:
                continue

            # Enqueue children
            left = node_id * 2 + 1
            right = node_id * 2 + 2
            queue.append((left, depth + 1))
            queue.append((right, depth + 1))

        # Draw leaf values ~ N(0, f_sigma2)
        f_sigma2 = tree_prior.f_sigma2
        leaf_ids = t.leaves
        t.leaf_vals[leaf_ids] = rng.normal(0.0, np.sqrt(f_sigma2), size=leaf_ids.size).astype(t.float_dtype)
        t.update_outputs()
        return t.evals.astype(np.float32), t

    # 2) Sum of trees
    f = np.zeros(n, dtype=np.float32)
    trees = []
    for _ in range(n_trees):
        f_tree, t = sample_tree_outputs_one_tree()
        f += f_tree
        if return_latent:
            trees.append(t)

    # 3) Noise variance prior and observations
    # sigma^2 ~ InvGamma(eps_nu/2, scale = eps_nu * eps_lambda / 2)
    sigma2 = float(invgamma.rvs(a=eps_nu / 2.0, scale=eps_nu * eps_lambda / 2.0, random_state=rng)) if eps_sigma2 is None else eps_sigma2
    y = f + rng.normal(0.0, np.sqrt(sigma2), size=n).astype(np.float32)

    if return_latent:
        return X, y, f, sigma2, trees
    return X, y
    
def generate_data_heatmap(output_dir: str | None = None, **kwargs) -> str:
    """
    Generate a heatmap of the DefaultBART prior f(x) for p=2.

    Returns:
    --------
    str
        Path to the generated heatmap file.
    """
    n = kwargs.pop('n', 10000)  # Extract n from kwargs, default to 10000
    res = generate_defaultbart_prior_with_cov(n, p=2, return_latent=True, **kwargs)
    X, y, f, sigma2, trees = res # type: ignore
    
    import matplotlib
    import matplotlib.pyplot as plt
    # Use a non-interactive backend for headless environments
    matplotlib.use('Agg')
    import os
    
    # Set default output directory if not provided
    if output_dir is None:
        # Use tests/output as default, relative to project root
        output_dir = 'tests/output'

    def _sum_trees(obs):
        return np.sum([t.evaluate(obs) for t in trees], axis=0)
    
    # Calculate f over a 2D grid to create a heatmap
    grid_size = 100
    x_grid = np.linspace(0, 1, grid_size)
    y_grid = np.linspace(0, 1, grid_size)
    X_grid, Y_grid = np.meshgrid(x_grid, y_grid)
    
    all_obs = np.stack([X_grid.ravel(), Y_grid.ravel()], axis=1)
    all_res = _sum_trees(all_obs)
    all_res_with_noise = all_res + np.random.normal(0.0, np.sqrt(sigma2), size=all_res.shape)

    def _save_heatmap(Z, title, filename):
        fig, ax = plt.subplots(figsize=(5, 4), dpi=150)
        im = ax.pcolormesh(
            X_grid, Y_grid,
            Z.reshape(grid_size, grid_size),
            cmap='viridis',
            shading='auto'
        )
        fig.colorbar(im, ax=ax)
        ax.set_title(title)
        ax.set_xlabel('x1')
        ax.set_ylabel('x2')
        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)
        out_path = os.path.join(output_dir, filename)
        fig.savefig(out_path, bbox_inches='tight')
        plt.close(fig)
        return out_path

    # Save heatmaps for f(x) and f(x)+noise
    out_path = _save_heatmap(all_res, 'DefaultBART prior f(x) heatmap (p=2)', 'generator_heatmap.png')
    _ = _save_heatmap(all_res_with_noise, 'DefaultBART prior f(x) + noise heatmap (p=2)', 'generator_heatmap_with_noise.png')

    return out_path

if __name__ == '__main__':
    generate_data_heatmap(n=10000, eps_sigma2=0.01)
    