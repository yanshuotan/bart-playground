{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test BinaryBART\n",
        "<sup>*</sup>Including ProbitBART and LogisticBART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score\n",
        "from sklearn.datasets import make_classification, load_breast_cancer, load_wine, fetch_openml\n",
        "import pandas as pd\n",
        "from bart_playground import *\n",
        "from bart_playground.bart import DefaultBART, ProbitBART\n",
        "import bartz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters\n",
        "N_TREES = 50\n",
        "NDPOST = 500\n",
        "NSKIP = 200\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# If debug then run with only one dataset and record running time\n",
        "# Otherwise run with all datasets\n",
        "debug = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, normalize\n",
        "\n",
        "def load_mushroom():\n",
        "    X, y = fetch_openml('mushroom', version=1, return_X_y=True)\n",
        "    for col in X.select_dtypes('category'):\n",
        "        # -1 in codes indicates NaN by pandas convention\n",
        "        X[col] = X[col].cat.codes\n",
        "    X = normalize(X)\n",
        "    y_array = y.to_numpy().reshape(-1, 1)\n",
        "    y_arm = OrdinalEncoder(dtype=int).fit_transform(y_array).flatten()\n",
        "    \n",
        "    return X, y_arm\n",
        "\n",
        "def load_mushroom_encoded():\n",
        "    X, y_arm = load_mushroom()\n",
        "    \n",
        "    n_arm = np.max(y_arm) + 1\n",
        "    dim = X.shape[1] * n_arm # total number of encoded covariates (location-encoded for each arm) \n",
        "    act_dim = X.shape[1] # number of covariates\n",
        "    covariates = np.zeros((n_arm * X.shape[0], dim))\n",
        "    rewards = np.zeros((n_arm * X.shape[0], ))\n",
        "    for cursor in range(X.shape[0]):\n",
        "        for a in range(n_arm):\n",
        "            covariates[cursor * n_arm + a, a * act_dim:(a * act_dim + act_dim)] = X[cursor]\n",
        "        arm = y_arm[cursor]\n",
        "        rewards[cursor * n_arm + arm] = 1\n",
        "\n",
        "    return covariates, rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "def load_datasets():\n",
        "    # Synthetic dataset\n",
        "    X_syn, y_syn = make_classification(n_samples=400, n_features=8, n_informative=6, \n",
        "                                       n_redundant=0, n_classes=2, random_state=RANDOM_STATE)\n",
        "    \n",
        "    # Breast cancer dataset\n",
        "    X_bc, y_bc = load_breast_cancer(return_X_y=True)\n",
        "    \n",
        "    # Wine dataset (convert to binary: class 0 vs rest)\n",
        "    X_wine, y_wine = load_wine(return_X_y=True)\n",
        "    y_wine = (y_wine == 0).astype(int)\n",
        "    \n",
        "    X_mushroom, y_mushroom = load_mushroom()\n",
        "    X_mr_encoded, y_mr_encoded = load_mushroom_encoded()\n",
        "    \n",
        "    return {\n",
        "        \"Synthetic\": (X_syn, y_syn),\n",
        "        \"Breast Cancer\": (X_bc, y_bc),\n",
        "        \"Wine Binary\": (X_wine, y_wine),\n",
        "        \"Mushroom\": (X_mushroom, y_mushroom),\n",
        "        \"Mushroom Encoded\": (X_mr_encoded, y_mr_encoded)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Evaluate a single model and return metrics\"\"\"\n",
        "    \n",
        "    if model_name == \"Bartz\":\n",
        "        # Bartz regression treating 0/1 as continuous\n",
        "        fit_result = bartz.BART.gbart(\n",
        "            x_train=X_train.T, y_train=y_train.astype(float),\n",
        "            x_test=X_test.T,\n",
        "            ntree=N_TREES, ndpost=NDPOST, nskip=NSKIP,\n",
        "            seed=RANDOM_STATE,\n",
        "            printevery=NDPOST + NSKIP + 100\n",
        "        )\n",
        "        btpred_all = fit_result.predict(np.transpose(X_test))\n",
        "        btpred = np.mean(np.array(btpred_all), axis=0)\n",
        "        y_pred_prob = np.clip(btpred, 1e-9, 1 - 1e-9)\n",
        "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "        \n",
        "    elif model_name == \"ProbitBART\" or model_name == \"LogisticBART\":\n",
        "        # Proper binary BART\n",
        "        model.fit(X_train, y_train)\n",
        "        proba_output = model.predict_proba(X_test)\n",
        "        y_pred_prob = proba_output[:, 1]\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "    elif model_name == \"RandomForestClassifier\":\n",
        "        # Native binary classifier\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "    else:\n",
        "        # Regression methods treating 0/1 as continuous\n",
        "        model.fit(X_train, y_train)\n",
        "        raw_pred = model.predict(X_test)\n",
        "        y_pred_prob = np.clip(raw_pred, 1e-9, 1 - 1e-9)\n",
        "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    logloss = log_loss(y_test, y_pred_prob)\n",
        "    auc = roc_auc_score(y_test, y_pred_prob)\n",
        "    \n",
        "    return {'Accuracy': accuracy, 'LogLoss': logloss, 'AUC': auc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bart_playground.bart import LogisticBART\n",
        "\n",
        "old_settings = np.seterr(invalid='raise')\n",
        "\n",
        "datasets = load_datasets()\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: Synthetic\n",
            "X shape: (400, 8), y shape: (400,)\n",
            "y distribution: {0: 0.5, 1: 0.5}\n",
            "Dataset: Breast Cancer\n",
            "X shape: (569, 30), y shape: (569,)\n",
            "y distribution: {1: 0.6274165202108963, 0: 0.37258347978910367}\n",
            "Dataset: Wine Binary\n",
            "X shape: (178, 13), y shape: (178,)\n",
            "y distribution: {0: 0.6685393258426966, 1: 0.33146067415730335}\n",
            "Dataset: Mushroom\n",
            "X shape: (8124, 22), y shape: (8124,)\n",
            "y distribution: {0: 0.517971442639094, 1: 0.48202855736090594}\n",
            "Dataset: Mushroom Encoded\n",
            "X shape: (16248, 44), y shape: (16248,)\n",
            "y distribution: {0.0: 0.5, 1.0: 0.5}\n"
          ]
        }
      ],
      "source": [
        "for name, (X, y) in datasets.items():\n",
        "    # Print dataset shapes\n",
        "    print(f\"Dataset: {name}\\nX shape: {X.shape}, y shape: {y.shape}\")\n",
        "    # Print 0-1 distribution of y\n",
        "    print(f\"y distribution: {pd.Series(y).value_counts(normalize=True).to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = None\n",
        " \n",
        "def record_evaluation_results(dataset_name, X, y):\n",
        "    global metrics\n",
        "    \n",
        "    print(f\"\\n=== Testing on {dataset_name} ===\")\n",
        "    \n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "    \n",
        "    # Define models\n",
        "    models = {\n",
        "        \"RFClassifier\": RandomForestClassifier(n_estimators=N_TREES, random_state=RANDOM_STATE),\n",
        "        \"RFRegressor\": RandomForestRegressor(n_estimators=N_TREES, random_state=RANDOM_STATE),\n",
        "        \"Bartz\": \"placeholder\",\n",
        "        \"DefaultBART\": DefaultBART(n_trees=N_TREES, ndpost=NDPOST, nskip=NSKIP, random_state=RANDOM_STATE),\n",
        "        \"ProbitBART\": ProbitBART(n_trees=N_TREES, ndpost=NDPOST, nskip=NSKIP, random_state=RANDOM_STATE),\n",
        "        \"LogisticBART\": LogisticBART(n_trees=N_TREES, ndpost=NDPOST, nskip=NSKIP, random_state=RANDOM_STATE)\n",
        "    }\n",
        "    \n",
        "    for model_name, model in models.items():\n",
        "        print(f\"  Training {model_name}...\")\n",
        "        \n",
        "        X_tr, X_te = X_train, X_test\n",
        "        \n",
        "        metrics = evaluate_model(model, model_name, X_tr, X_te, y_train, y_test)\n",
        "        \n",
        "        result = {'Dataset': dataset_name, 'Model': model_name, **metrics}\n",
        "        results.append(result)\n",
        "        print(f\"    Acc: {metrics['Accuracy']:.3f}, LogLoss: {metrics['LogLoss']:.3f}, AUC: {metrics['AUC']:.4f}\")\n",
        "        \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:2025-06-08 10:56:38,504:jax._src.xla_bridge:867: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
            "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Testing on Synthetic ===\n",
            "  Training RFClassifier...\n",
            "    Acc: 0.900, LogLoss: 2.072, AUC: 0.9000\n",
            "  Training RFRegressor...\n",
            "    Acc: 0.858, LogLoss: 0.341, AUC: 0.9315\n",
            "  Training Bartz...\n",
            "    Acc: 0.875, LogLoss: 0.329, AUC: 0.9475\n",
            "  Training DefaultBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:11<00:00, 59.95it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.867, LogLoss: 0.322, AUC: 0.9511\n",
            "  Training ProbitBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:08<00:00, 85.04it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.817, LogLoss: 0.552, AUC: 0.8756\n",
            "  Training LogisticBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:15<00:00, 43.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.867, LogLoss: 0.313, AUC: 0.9497\n",
            "\n",
            "=== Testing on Breast Cancer ===\n",
            "  Training RFClassifier...\n",
            "    Acc: 0.924, LogLoss: 1.575, AUC: 0.9204\n",
            "  Training RFRegressor...\n",
            "    Acc: 0.942, LogLoss: 0.118, AUC: 0.9892\n",
            "  Training Bartz...\n",
            "    Acc: 0.947, LogLoss: 0.172, AUC: 0.9848\n",
            "  Training DefaultBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:06<00:00, 103.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.942, LogLoss: 0.140, AUC: 0.9857\n",
            "  Training ProbitBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:06<00:00, 100.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.936, LogLoss: 0.264, AUC: 0.9879\n",
            "  Training LogisticBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:13<00:00, 51.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.971, LogLoss: 0.107, AUC: 0.9931\n",
            "\n",
            "=== Testing on Wine Binary ===\n",
            "  Training RFClassifier...\n",
            "    Acc: 0.926, LogLoss: 1.535, AUC: 0.9028\n",
            "  Training RFRegressor...\n",
            "    Acc: 0.926, LogLoss: 0.519, AUC: 0.9498\n",
            "  Training Bartz...\n",
            "    Acc: 0.944, LogLoss: 0.124, AUC: 0.9877\n",
            "  Training DefaultBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:04<00:00, 144.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.963, LogLoss: 0.132, AUC: 0.9846\n",
            "  Training ProbitBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:06<00:00, 115.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.815, LogLoss: 0.463, AUC: 0.9861\n",
            "  Training LogisticBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:12<00:00, 54.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.944, LogLoss: 0.135, AUC: 0.9892\n",
            "\n",
            "=== Testing on Mushroom ===\n",
            "  Training RFClassifier...\n",
            "    Acc: 1.000, LogLoss: 0.000, AUC: 1.0000\n",
            "  Training RFRegressor...\n",
            "    Acc: 1.000, LogLoss: 0.002, AUC: 1.0000\n",
            "  Training Bartz...\n",
            "    Acc: 1.000, LogLoss: 0.003, AUC: 1.0000\n",
            "  Training DefaultBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [01:34<00:00,  7.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 1.000, LogLoss: 0.015, AUC: 1.0000\n",
            "  Training ProbitBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:46<00:00, 15.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.979, LogLoss: 0.091, AUC: 0.9984\n",
            "  Training LogisticBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 700/700 [00:41<00:00, 16.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.996, LogLoss: 0.026, AUC: 0.9999\n"
          ]
        }
      ],
      "source": [
        "if not debug:\n",
        "    for dataset_name, (X, y) in list(datasets.items())[0:4]: # skip mushroom encoded for brevity\n",
        "        record_evaluation_results(dataset_name, X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Testing on Mushroom Encoded ===\n",
            "  Training RFClassifier...\n",
            "    Acc: 1.000, LogLoss: 0.004, AUC: 0.9998\n",
            "  Training RFRegressor...\n",
            "    Acc: 0.999, LogLoss: 0.008, AUC: 0.9998\n",
            "  Training LogisticBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 400/400 [01:02<00:00,  6.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.997, LogLoss: 0.028, AUC: 0.9999\n"
          ]
        }
      ],
      "source": [
        "if debug == True:\n",
        "    dataset_name, (X, y) = list(datasets.items())[-1]  # Last dataset for debugging\n",
        "    \n",
        "    profile = False\n",
        "    if not profile:\n",
        "        record_evaluation_results(dataset_name, X, y)\n",
        "    else:\n",
        "        %prun -s cumtime -D temp_profile.prof -q record_evaluation_results(dataset_name, X, y)\n",
        "\n",
        "        fname = \"profile_logisticbart\"\n",
        "\n",
        "        !mv temp_profile.prof {fname}.prof\n",
        "        !gprof2dot -f pstats {fname}.prof -o {fname}.dot\n",
        "        !dot -Tpng {fname}.dot -o {fname}.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "SUMMARY RESULTS\n",
            "============================================================\n",
            "\n",
            "Accuracy:\n",
            "Model          Bartz  DefaultBART  LogisticBART  ProbitBART  RFClassifier  \\\n",
            "Dataset                                                                     \n",
            "Breast Cancer  0.947        0.942         0.971       0.936         0.924   \n",
            "Synthetic      0.875        0.867         0.867       0.817         0.900   \n",
            "Wine Binary    0.944        0.963         0.944       0.815         0.926   \n",
            "\n",
            "Model          RFRegressor  \n",
            "Dataset                     \n",
            "Breast Cancer        0.942  \n",
            "Synthetic            0.858  \n",
            "Wine Binary          0.926  \n",
            "\n",
            "AUC:\n",
            "Model          Bartz  DefaultBART  LogisticBART  ProbitBART  RFClassifier  \\\n",
            "Dataset                                                                     \n",
            "Breast Cancer  0.985        0.986         0.993       0.988         0.920   \n",
            "Synthetic      0.948        0.951         0.950       0.876         0.900   \n",
            "Wine Binary    0.988        0.985         0.989       0.986         0.903   \n",
            "\n",
            "Model          RFRegressor  \n",
            "Dataset                     \n",
            "Breast Cancer        0.989  \n",
            "Synthetic            0.932  \n",
            "Wine Binary          0.950  \n",
            "\n",
            "LogLoss:\n",
            "Model          Bartz  DefaultBART  LogisticBART  ProbitBART  RFClassifier  \\\n",
            "Dataset                                                                     \n",
            "Breast Cancer  0.172        0.140         0.107       0.264         1.575   \n",
            "Synthetic      0.329        0.322         0.313       0.552         2.072   \n",
            "Wine Binary    0.124        0.132         0.135       0.463         1.535   \n",
            "\n",
            "Model          RFRegressor  \n",
            "Dataset                     \n",
            "Breast Cancer        0.118  \n",
            "Synthetic            0.341  \n",
            "Wine Binary          0.519  \n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Pivot tables for easy comparison\n",
        "for metric in ['Accuracy', 'AUC', 'LogLoss']:\n",
        "    print(f\"\\n{metric}:\")\n",
        "    pivot = results_df.pivot_table(index='Dataset', columns='Model', values=metric)\n",
        "    print(pivot.round(3))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "bartpg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
