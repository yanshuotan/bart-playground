{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test BinaryBART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score\n",
        "from sklearn.datasets import make_classification, load_breast_cancer, load_wine\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from bart_playground import *\n",
        "from bart_playground.bart import DefaultBART, BinaryBART\n",
        "import bartz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters\n",
        "N_TREES = 50\n",
        "NDPOST = 500\n",
        "NSKIP = 500\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "def load_datasets():\n",
        "    # Synthetic dataset\n",
        "    X_syn, y_syn = make_classification(n_samples=400, n_features=8, n_informative=6, \n",
        "                                       n_redundant=0, n_classes=2, random_state=RANDOM_STATE)\n",
        "    \n",
        "    # Breast cancer dataset\n",
        "    X_bc, y_bc = load_breast_cancer(return_X_y=True)\n",
        "    \n",
        "    # Wine dataset (convert to binary: class 0 vs rest)\n",
        "    X_wine, y_wine = load_wine(return_X_y=True)\n",
        "    y_wine = (y_wine == 0).astype(int)\n",
        "    \n",
        "    return {\n",
        "        \"Synthetic\": (X_syn, y_syn),\n",
        "        \"Breast Cancer\": (X_bc, y_bc),\n",
        "        \"Wine Binary\": (X_wine, y_wine)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Evaluate a single model and return metrics\"\"\"\n",
        "    \n",
        "    if model_name == \"Bartz\":\n",
        "        # Bartz regression treating 0/1 as continuous\n",
        "        fit_result = bartz.BART.gbart(\n",
        "            x_train=X_train.T, y_train=y_train.astype(float),\n",
        "            x_test=X_test.T,\n",
        "            ntree=N_TREES, ndpost=NDPOST, nskip=NSKIP,\n",
        "            seed=RANDOM_STATE,\n",
        "            printevery=NDPOST + NSKIP + 100\n",
        "        )\n",
        "        btpred_all = fit_result.predict(np.transpose(X_test))\n",
        "        btpred = np.mean(np.array(btpred_all), axis=0)\n",
        "        y_pred_prob = np.clip(btpred, 1e-9, 1 - 1e-9)\n",
        "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "        \n",
        "    elif model_name == \"BinaryBART\" or model_name == \"LogisticBART\":\n",
        "        # Proper binary BART\n",
        "        model.fit(X_train, y_train)\n",
        "        proba_output = model.predict_proba(X_test)\n",
        "        y_pred_prob = proba_output[:, 1]\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "    elif model_name == \"RandomForestClassifier\":\n",
        "        # Native binary classifier\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "    else:\n",
        "        # Regression methods treating 0/1 as continuous\n",
        "        model.fit(X_train, y_train)\n",
        "        raw_pred = model.predict(X_test)\n",
        "        y_pred_prob = np.clip(raw_pred, 1e-9, 1 - 1e-9)\n",
        "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    logloss = log_loss(y_test, y_pred_prob)\n",
        "    auc = roc_auc_score(y_test, y_pred_prob)\n",
        "    \n",
        "    return {'Accuracy': accuracy, 'LogLoss': logloss, 'AUC': auc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Testing on Synthetic ===\n",
            "  Training RandomForestClassifier...\n",
            "    Acc: 0.900, LogLoss: 0.318, AUC: 0.956\n",
            "  Training RandomForestRegressor...\n",
            "    Acc: 0.858, LogLoss: 0.341, AUC: 0.932\n",
            "  Training DefaultBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 200/200 [00:15<00:00, 12.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.875, LogLoss: 0.311, AUC: 0.964\n",
            "  Training LogisticBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 750/750 [07:12<00:00,  1.73it/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.525, LogLoss: 0.695, AUC: 0.422\n",
            "\n",
            "=== Testing on Breast Cancer ===\n",
            "  Training RandomForestClassifier...\n",
            "    Acc: 0.924, LogLoss: 0.124, AUC: 0.991\n",
            "  Training RandomForestRegressor...\n",
            "    Acc: 0.942, LogLoss: 0.118, AUC: 0.989\n",
            "  Training DefaultBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 200/200 [00:03<00:00, 65.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.953, LogLoss: 0.123, AUC: 0.992\n",
            "  Training LogisticBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 750/750 [00:38<00:00, 19.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.380, LogLoss: 0.695, AUC: 0.533\n",
            "\n",
            "=== Testing on Wine Binary ===\n",
            "  Training RandomForestClassifier...\n",
            "    Acc: 0.926, LogLoss: 0.155, AUC: 0.992\n",
            "  Training RandomForestRegressor...\n",
            "    Acc: 0.926, LogLoss: 0.519, AUC: 0.950\n",
            "  Training DefaultBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 200/200 [00:02<00:00, 76.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.944, LogLoss: 0.122, AUC: 0.988\n",
            "  Training LogisticBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterations: 100%|██████████| 750/750 [00:28<00:00, 25.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Acc: 0.444, LogLoss: 0.696, AUC: 0.400\n"
          ]
        }
      ],
      "source": [
        "# Main evaluation loop\n",
        "from bart_playground.bart import LogisticBART\n",
        "\n",
        "datasets = load_datasets()\n",
        "results = []\n",
        "\n",
        "for dataset_name, (X, y) in datasets.items():\n",
        "    print(f\"\\n=== Testing on {dataset_name} ===\")\n",
        "    \n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "    \n",
        "    # Define models\n",
        "    models = {\n",
        "        \"RandomForestClassifier\": RandomForestClassifier(n_estimators=N_TREES, random_state=RANDOM_STATE),\n",
        "        \"RandomForestRegressor\": RandomForestRegressor(n_estimators=N_TREES, random_state=RANDOM_STATE),\n",
        "        \"DefaultBART\": DefaultBART(n_trees=N_TREES, ndpost=NDPOST // 5, nskip=NSKIP // 5, random_state=RANDOM_STATE),\n",
        "        # \"BinaryBART\": BinaryBART(n_trees=N_TREES, ndpost=NDPOST, nskip=NSKIP, random_state=RANDOM_STATE),\n",
        "        \"LogisticBART\": LogisticBART(n_trees=N_TREES // 2, ndpost=NDPOST, nskip=NSKIP // 2, random_state=RANDOM_STATE),\n",
        "        # \"Bartz\": \"placeholder\"\n",
        "    }\n",
        "    \n",
        "    for model_name, model in models.items():\n",
        "        print(f\"  Training {model_name}...\")\n",
        "        \n",
        "        X_tr, X_te = X_train, X_test\n",
        "            \n",
        "        metrics = evaluate_model(model, model_name, X_tr, X_te, y_train, y_test)\n",
        "        \n",
        "        result = {'Dataset': dataset_name, 'Model': model_name, **metrics}\n",
        "        results.append(result)\n",
        "        \n",
        "        print(f\"    Acc: {metrics['Accuracy']:.3f}, LogLoss: {metrics['LogLoss']:.3f}, AUC: {metrics['AUC']:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "SUMMARY RESULTS\n",
            "============================================================\n",
            "\n",
            "Accuracy:\n",
            "Model          Bartz  BinaryBART  DefaultBART  RandomForestClassifier  \\\n",
            "Dataset                                                                 \n",
            "Breast Cancer  0.947       0.942        0.936                   0.924   \n",
            "Synthetic      0.883       0.775        0.867                   0.900   \n",
            "Wine Binary    0.944       0.815        0.963                   0.926   \n",
            "\n",
            "Model          RandomForestRegressor  \n",
            "Dataset                               \n",
            "Breast Cancer                  0.942  \n",
            "Synthetic                      0.858  \n",
            "Wine Binary                    0.926  \n",
            "\n",
            "AUC:\n",
            "Model          Bartz  BinaryBART  DefaultBART  RandomForestClassifier  \\\n",
            "Dataset                                                                 \n",
            "Breast Cancer  0.991       0.989        0.984                   0.991   \n",
            "Synthetic      0.949       0.871        0.952                   0.956   \n",
            "Wine Binary    0.994       0.977        0.985                   0.992   \n",
            "\n",
            "Model          RandomForestRegressor  \n",
            "Dataset                               \n",
            "Breast Cancer                  0.989  \n",
            "Synthetic                      0.932  \n",
            "Wine Binary                    0.950  \n",
            "\n",
            "LogLoss:\n",
            "Model          Bartz  BinaryBART  DefaultBART  RandomForestClassifier  \\\n",
            "Dataset                                                                 \n",
            "Breast Cancer  0.130       0.267        0.146                   0.124   \n",
            "Synthetic      0.329       0.550        0.319                   0.318   \n",
            "Wine Binary    0.117       0.479        0.138                   0.155   \n",
            "\n",
            "Model          RandomForestRegressor  \n",
            "Dataset                               \n",
            "Breast Cancer                  0.118  \n",
            "Synthetic                      0.341  \n",
            "Wine Binary                    0.519  \n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Pivot tables for easy comparison\n",
        "for metric in ['Accuracy', 'AUC', 'LogLoss']:\n",
        "    print(f\"\\n{metric}:\")\n",
        "    pivot = results_df.pivot_table(index='Dataset', columns='Model', values=metric)\n",
        "    print(pivot.round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Models per Dataset:\n",
            "\n",
            "Synthetic:\n",
            "  Best Accuracy: RandomForestClassifier (0.900)\n",
            "  Best AUC: RandomForestClassifier (0.956)\n",
            "  Best LogLoss: RandomForestClassifier (0.318)\n",
            "\n",
            "Breast Cancer:\n",
            "  Best Accuracy: Bartz (0.947)\n",
            "  Best AUC: RandomForestClassifier (0.991)\n",
            "  Best LogLoss: RandomForestRegressor (0.118)\n",
            "\n",
            "Wine Binary:\n",
            "  Best Accuracy: DefaultBART (0.963)\n",
            "  Best AUC: Bartz (0.994)\n",
            "  Best LogLoss: Bartz (0.117)\n",
            "\n",
            "Testing complete!\n"
          ]
        }
      ],
      "source": [
        "# Best model per dataset\n",
        "print(\"\\nBest Models per Dataset:\")\n",
        "for dataset in results_df['Dataset'].unique():\n",
        "    dataset_results = results_df[results_df['Dataset'] == dataset]\n",
        "    \n",
        "    best_acc = dataset_results.loc[dataset_results['Accuracy'].idxmax()]\n",
        "    best_auc = dataset_results.loc[dataset_results['AUC'].idxmax()]\n",
        "    best_ll = dataset_results.loc[dataset_results['LogLoss'].idxmin()]\n",
        "    \n",
        "    print(f\"\\n{dataset}:\")\n",
        "    print(f\"  Best Accuracy: {best_acc['Model']} ({best_acc['Accuracy']:.3f})\")\n",
        "    print(f\"  Best AUC: {best_auc['Model']} ({best_auc['AUC']:.3f})\")\n",
        "    print(f\"  Best LogLoss: {best_ll['Model']} ({best_ll['LogLoss']:.3f})\")\n",
        "\n",
        "print(\"\\nTesting complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "bartpg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
