{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Multi-class Classification\n",
    "<sup>*</sup>Including LogisticBART for n_cat > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification, load_wine, load_iris\n",
    "import pandas as pd\n",
    "from bart_playground import *\n",
    "from bart_playground.bart import LogisticBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N_TREES = 25\n",
    "NDPOST = 1000\n",
    "NSKIP = 200\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "def load_datasets():\n",
    "    # Synthetic 3-class dataset\n",
    "    X_syn, y_syn = make_classification(n_samples=400, n_features=8, n_informative=6, \n",
    "                                       n_redundant=0, n_classes=3, n_clusters_per_class=1,\n",
    "                                       random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Iris dataset (3 classes)\n",
    "    X_iris, y_iris = load_iris(return_X_y=True)\n",
    "    \n",
    "    # Wine dataset (3 classes)\n",
    "    X_wine, y_wine = load_wine(return_X_y=True)\n",
    "    \n",
    "    # Synthetic 4-class dataset\n",
    "    X_syn4, y_syn4 = make_classification(n_samples=600, n_features=10, n_informative=8,\n",
    "                                         n_redundant=0, n_classes=4, n_clusters_per_class=1,\n",
    "                                         random_state=RANDOM_STATE)\n",
    "    \n",
    "    return {\n",
    "        \"Synthetic 3-class\": (X_syn, y_syn),\n",
    "        \"Iris\": (X_iris, y_iris),\n",
    "        \"Wine\": (X_wine, y_wine),\n",
    "        \"Synthetic 4-class\": (X_syn4, y_syn4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Evaluate a single model and return metrics\"\"\"\n",
    "    \n",
    "    if model_name == \"LogisticBART\":\n",
    "        # Multi-class LogisticBART\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "    elif model_name == \"RFClassifier\":\n",
    "        # Multi-class Random Forest\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    logloss = log_loss(y_test, y_pred_proba)\n",
    "    auc_ovr = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "\n",
    "    return {'Accuracy': accuracy, 'LogLoss': logloss, 'AUC_OvR': auc_ovr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If debug then run with only one dataset and record running time\n",
    "# Otherwise run with all datasets\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_settings = np.seterr(invalid='raise')\n",
    "\n",
    "datasets = load_datasets()\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Synthetic 3-class\n",
      "X shape: (400, 8), y shape: (400,)\n",
      "Class distribution: {0: 0.3375, 1: 0.33, 2: 0.3325}\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: Iris\n",
      "X shape: (150, 4), y shape: (150,)\n",
      "Class distribution: {0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: Wine\n",
      "X shape: (178, 13), y shape: (178,)\n",
      "Class distribution: {0: 0.33146067415730335, 1: 0.398876404494382, 2: 0.2696629213483146}\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: Synthetic 4-class\n",
      "X shape: (600, 10), y shape: (600,)\n",
      "Class distribution: {0: 0.24666666666666667, 1: 0.24833333333333332, 2: 0.25666666666666665, 3: 0.24833333333333332}\n",
      "Number of classes: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, (X, y) in datasets.items():\n",
    "    # Print dataset shapes\n",
    "    print(f\"Dataset: {name}\\nX shape: {X.shape}, y shape: {y.shape}\")\n",
    "    # Print class distribution\n",
    "    print(f\"Class distribution: {pd.Series(y).value_counts(normalize=True).sort_index().to_dict()}\")\n",
    "    print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing on Synthetic 3-class ===\n",
      "  Training RFClassifier...\n",
      "    Acc: 0.850, LogLoss: 0.416, AUC_OvR: 0.961\n",
      "  Training LogisticBART...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 1200/1200 [00:17<00:00, 67.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Acc: 0.842, LogLoss: 0.371, AUC_OvR: 0.967\n",
      "\n",
      "=== Testing on Iris ===\n",
      "  Training RFClassifier...\n",
      "    Acc: 0.889, LogLoss: 0.194, AUC_OvR: 0.989\n",
      "  Training LogisticBART...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 1200/1200 [00:22<00:00, 53.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Acc: 0.911, LogLoss: 0.194, AUC_OvR: 0.993\n",
      "\n",
      "=== Testing on Wine ===\n",
      "  Training RFClassifier...\n",
      "    Acc: 1.000, LogLoss: 0.130, AUC_OvR: 1.000\n",
      "  Training LogisticBART...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 1200/1200 [00:15<00:00, 76.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Acc: 1.000, LogLoss: 0.155, AUC_OvR: 1.000\n",
      "\n",
      "=== Testing on Synthetic 4-class ===\n",
      "  Training RFClassifier...\n",
      "    Acc: 0.844, LogLoss: 0.557, AUC_OvR: 0.968\n",
      "  Training LogisticBART...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 1200/1200 [00:20<00:00, 57.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Acc: 0.833, LogLoss: 0.543, AUC_OvR: 0.954\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f\"\\n=== Testing on {dataset_name} ===\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Define models\n",
    "    models = {\n",
    "        \"RFClassifier\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "        \"LogisticBART\": LogisticBART(n_trees=N_TREES, ndpost=NDPOST, nskip=NSKIP, random_state=RANDOM_STATE)\n",
    "    }\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"  Training {model_name}...\")\n",
    "        \n",
    "        X_tr, X_te = X_train, X_test\n",
    "        \n",
    "        if(debug == True):\n",
    "            continue    \n",
    "        metrics = evaluate_model(model, model_name, X_tr, X_te, y_train, y_test)\n",
    "        \n",
    "        result = {'Dataset': dataset_name, 'Model': model_name, **metrics}\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"    Acc: {metrics['Accuracy']:.3f}, LogLoss: {metrics['LogLoss']:.3f}, AUC_OvR: {metrics['AUC_OvR']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = None\n",
    " \n",
    "def record_evaluation_results():\n",
    "    global metrics\n",
    "    X_tr, X_te = X_train, X_test\n",
    "    metrics = evaluate_model(model, model_name, X_tr, X_te, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug == True:\n",
    "    X_tr, X_te = X_train, X_test\n",
    "    record_evaluation_results()\n",
    "    \n",
    "    # %prun -s cumtime -D temp_profile.prof -q record_evaluation_results()\n",
    "\n",
    "    # fname = \"profile_multiclass_logisticbart\"\n",
    "\n",
    "    # !mv temp_profile.prof {fname}.prof\n",
    "    # !gprof2dot -f pstats {fname}.prof -o {fname}.dot\n",
    "    # !dot -Tpng {fname}.dot -o {fname}.png\n",
    "    \n",
    "    result = {'Dataset': dataset_name, 'Model': model_name, **metrics}\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"    Acc: {metrics['Accuracy']:.3f}, LogLoss: {metrics['LogLoss']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY RESULTS\n",
      "============================================================\n",
      "\n",
      "Accuracy:\n",
      "Model              LogisticBART  RFClassifier\n",
      "Dataset                                      \n",
      "Iris                      0.911         0.889\n",
      "Synthetic 3-class         0.842         0.850\n",
      "Synthetic 4-class         0.833         0.844\n",
      "Wine                      1.000         1.000\n",
      "\n",
      "LogLoss:\n",
      "Model              LogisticBART  RFClassifier\n",
      "Dataset                                      \n",
      "Iris                      0.194         0.194\n",
      "Synthetic 3-class         0.371         0.416\n",
      "Synthetic 4-class         0.543         0.557\n",
      "Wine                      0.155         0.130\n",
      "\n",
      "AUC_OvR:\n",
      "Model              LogisticBART  RFClassifier\n",
      "Dataset                                      \n",
      "Iris                      0.993         0.989\n",
      "Synthetic 3-class         0.967         0.961\n",
      "Synthetic 4-class         0.954         0.968\n",
      "Wine                      1.000         1.000\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Pivot tables for easy comparison\n",
    "for metric in ['Accuracy', 'LogLoss', 'AUC_OvR']:\n",
    "    print(f\"\\n{metric}:\")\n",
    "    pivot = results_df.pivot_table(index='Dataset', columns='Model', values=metric)\n",
    "    print(pivot.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bartpg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
