{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DefaultBART, MultiChainBART for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "from bart_playground import *\n",
    "from bart_playground.bart import DefaultBART\n",
    "from bart_playground.mcbart import MultiChainBART\n",
    "from xgboost import XGBRegressor\n",
    "import bartz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N_TREES = 50\n",
    "NDPOST = 1000\n",
    "NSKIP = 200\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# If debug then run with only one dataset and record running time\n",
    "# Otherwise run with all datasets\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "def load_datasets():\n",
    "    # Friedman regression dataset\n",
    "    generator = DataGenerator(n_samples=1000, n_features=5, noise=1, random_seed=RANDOM_STATE)\n",
    "    X_friedman, y_friedman = generator.generate(scenario=\"friedman1\")\n",
    "\n",
    "    return {\n",
    "        \"Friedman1\": (X_friedman, y_friedman)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test, dataset_name):\n",
    "    \"\"\"Evaluate a single model and return regression metrics\"\"\"\n",
    "    time_start = time.time()\n",
    "    if model_name == \"Bartz\":\n",
    "        # Bartz regression\n",
    "        fit_result = bartz.BART.gbart(\n",
    "            x_train=X_train.T, y_train=y_train.astype(float),\n",
    "            x_test=X_test.T,\n",
    "            ntree=N_TREES, ndpost=NDPOST, nskip=NSKIP,\n",
    "            seed=RANDOM_STATE,\n",
    "            printevery=NDPOST + NSKIP + 100\n",
    "        )\n",
    "        btpred_all = fit_result.predict(np.transpose(X_test))\n",
    "        y_pred = np.mean(np.array(btpred_all), axis=0)\n",
    "    else:\n",
    "        # Standard regression models\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    time_end = time.time()\n",
    "    \n",
    "    # Calculate regression metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return {'MSE': mse, 'MAE': mae, 'R2': r2, 'Time': time_end - time_start}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = None\n",
    "results = []\n",
    " \n",
    "def record_evaluation_results(dataset_name, X, y):\n",
    "    global metrics\n",
    "    \n",
    "    print(f\"\\n=== Testing on {dataset_name} ====\")\n",
    "    \n",
    "    # Split data (no stratification needed for regression)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # Define regression models only\n",
    "    models = {\n",
    "        \"XGBRegressor\": XGBRegressor(n_estimators=N_TREES, random_state=RANDOM_STATE),\n",
    "        \"RFRegressor\": RandomForestRegressor(n_estimators=N_TREES, random_state=RANDOM_STATE),\n",
    "        \"MultiChainBART\": MultiChainBART(n_ensembles=4, bart_class = DefaultBART, random_state=RANDOM_STATE, n_trees=N_TREES, ndpost=NDPOST//4, nskip=NSKIP//4),\n",
    "        \"Bartz\": \"placeholder\",\n",
    "        \"DefaultBART\": DefaultBART(n_trees=N_TREES, ndpost=NDPOST, nskip=NSKIP, random_state=RANDOM_STATE)\n",
    "    }\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"  Training {model_name}...\")\n",
    "        \n",
    "        X_tr, X_te = X_train, X_test\n",
    "        \n",
    "        metrics = evaluate_model(model, model_name, X_tr, X_te, y_train, y_test, dataset_name)\n",
    "        \n",
    "        result = {'Dataset': dataset_name, 'Model': model_name, **metrics}\n",
    "        results.append(result)\n",
    "        print(f\"    MSE: {metrics['MSE']:.3f}, MAE: {metrics['MAE']:.3f}, \"\n",
    "              f\"R2: {metrics['R2']:.4f}, Time: {metrics['Time']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_settings = np.seterr(invalid='raise')\n",
    "\n",
    "datasets = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Friedman1\n",
      "X shape: (1000, 5), y shape: (1000,)\n",
      "y statistics:\n",
      "  Mean: 14.342, Std: 5.099\n",
      "  Min: 0.354, Max: 28.031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, (X, y) in datasets.items():\n",
    "    # Print dataset shapes\n",
    "    print(f\"Dataset: {name}\\nX shape: {X.shape}, y shape: {y.shape}\")\n",
    "    # Print target variable statistics for regression\n",
    "    print(f\"y statistics:\")\n",
    "    print(f\"  Mean: {y.mean():.3f}, Std: {y.std():.3f}\")\n",
    "    print(f\"  Min: {y.min():.3f}, Max: {y.max():.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not debug:\n",
    "    for dataset_name, (X, y) in list(datasets.items()):\n",
    "        record_evaluation_results(dataset_name, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing on Friedman1 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:48:39,021\tINFO worker.py:1908 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 BARTActor(s).\n",
      "  Training XGBRegressor...\n",
      "    MSE: 2.663, MAE: 1.337, R2: 0.8878, Time: 2.11s\n",
      "  Training RFRegressor...\n",
      "    MSE: 3.356, MAE: 1.469, R2: 0.8586, Time: 0.14s\n",
      "  Training MultiChainBART...\n",
      "    MSE: 2.663, MAE: 1.337, R2: 0.8878, Time: 2.11s\n",
      "  Training RFRegressor...\n",
      "    MSE: 3.356, MAE: 1.469, R2: 0.8586, Time: 0.14s\n",
      "  Training MultiChainBART...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:   0%|          | 0/300 [00:00<?, ?it/s]\n",
      "Iterations:   0%|          | 1/300 [00:05<25:13,  5.06s/it]\n",
      "Iterations:   0%|          | 0/300 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Iterations:   0%|          | 1/300 [00:05<25:13,  5.06s/it]\n",
      "Iterations:   0%|          | 0/300 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Iterations:  94%|█████████▎| 281/300 [00:09<00:00, 88.92it/s]\n",
      "Iterations:  94%|█████████▎| 281/300 [00:09<00:00, 88.92it/s]\n",
      "Iterations: 100%|██████████| 300/300 [00:09<00:00, 32.10it/s]\n",
      "Iterations: 100%|██████████| 300/300 [00:09<00:00, 32.10it/s]\n",
      "Iterations:  89%|████████▉ | 267/300 [00:09<00:00, 78.73it/s]\u001b[32m [repeated 126x across cluster]\u001b[0m\n",
      "Iterations:  89%|████████▉ | 267/300 [00:09<00:00, 78.73it/s]\u001b[32m [repeated 126x across cluster]\u001b[0m\n",
      "INFO:2025-06-13 14:48:52,698:jax._src.xla_bridge:867: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "INFO:2025-06-13 14:48:52,698:jax._src.xla_bridge:867: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MSE: 1.251, MAE: 0.916, R2: 0.9473, Time: 10.76s\n",
      "  Training Bartz...\n",
      "    MSE: 1.792, MAE: 1.062, R2: 0.9245, Time: 8.03s\n",
      "  Training DefaultBART...\n",
      "    MSE: 1.792, MAE: 1.062, R2: 0.9245, Time: 8.03s\n",
      "  Training DefaultBART...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 1200/1200 [00:18<00:00, 64.18it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MSE: 1.799, MAE: 1.058, R2: 0.9242, Time: 20.49s\n"
     ]
    }
   ],
   "source": [
    "if debug == True:\n",
    "    dataset_name, (X, y) = list(datasets.items())[-1]  # Last dataset for debugging\n",
    "    \n",
    "    profile = False\n",
    "    if not profile:\n",
    "        record_evaluation_results(dataset_name, X, y)\n",
    "    else:\n",
    "        %prun -s cumtime -D temp_profile.prof -q record_evaluation_results(dataset_name, X, y)\n",
    "\n",
    "        fname = \"profile_mcbart\"\n",
    "\n",
    "        !mv temp_profile.prof {fname}.prof\n",
    "        !gprof2dot -f pstats {fname}.prof -o {fname}.dot\n",
    "        !dot -Tpng {fname}.dot -o {fname}.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY RESULTS\n",
      "============================================================\n",
      "\n",
      "MSE:\n",
      "Model      Bartz  DefaultBART  MultiChainBART  RFRegressor  XGBRegressor\n",
      "Dataset                                                                 \n",
      "Friedman1  1.792        1.799           1.251        3.356         2.663\n",
      "\n",
      "MAE:\n",
      "Model      Bartz  DefaultBART  MultiChainBART  RFRegressor  XGBRegressor\n",
      "Dataset                                                                 \n",
      "Friedman1  1.062        1.058           0.916        1.469         1.337\n",
      "\n",
      "R2:\n",
      "Model      Bartz  DefaultBART  MultiChainBART  RFRegressor  XGBRegressor\n",
      "Dataset                                                                 \n",
      "Friedman1  0.924        0.924           0.947        0.859         0.888\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Pivot tables for easy comparison\n",
    "for metric in ['MSE', 'MAE', 'R2']:\n",
    "    print(f\"\\n{metric}:\")\n",
    "    pivot = results_df.pivot_table(index='Dataset', columns='Model', values=metric)\n",
    "    print(pivot.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MCBART update_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MCBART update_fit with incremental samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 15:30:08,877\tINFO worker.py:1908 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 BARTActor(s).\n",
      "Time taken for incremental updates: 50.97 seconds\n",
      "MCBART update_fit results:\n",
      "  MSE: 1.316, MAE: 0.917, R2: 0.9445\n",
      "Time taken for incremental updates: 50.97 seconds\n",
      "MCBART update_fit results:\n",
      "  MSE: 1.316, MAE: 0.917, R2: 0.9445\n"
     ]
    }
   ],
   "source": [
    "# Test MCBART update_fit with one-by-one updates\n",
    "print(\"Testing MCBART update_fit with incremental samples...\")\n",
    "\n",
    "# Use the Friedman dataset\n",
    "X, y = datasets[\"Friedman1\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# Initialize MCBART with initial training data (first 10% of training set)\n",
    "initial_size = int(0.1 * len(X_train))\n",
    "X_initial = X_train[:initial_size]\n",
    "y_initial = y_train[:initial_size]\n",
    "X_update = X_train[initial_size:]\n",
    "y_update = y_train[initial_size:]\n",
    "\n",
    "# record total time\n",
    "import time\n",
    "start_time = time.time()\n",
    "# Fit MCBART initially\n",
    "mcbart_update = MultiChainBART(n_ensembles=4, bart_class=DefaultBART, \n",
    "                               random_state=RANDOM_STATE, \n",
    "                               n_trees=N_TREES, ndpost=NDPOST, nskip=NSKIP)\n",
    "mcbart_update.fit(X_initial, y_initial, quietly=True)\n",
    "\n",
    "# Update one sample at a time\n",
    "for i in range(len(X_update)):\n",
    "    mcbart_update.update_fit(X_update[i:i+1], y_update[i:i+1], add_ndpost=3, quietly=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken for incremental updates: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate final model\n",
    "y_pred_update = mcbart_update.predict(X_test)\n",
    "mse_update = mean_squared_error(y_test, y_pred_update)\n",
    "mae_update = mean_absolute_error(y_test, y_pred_update)\n",
    "r2_update = r2_score(y_test, y_pred_update)\n",
    "\n",
    "print(f\"MCBART update_fit results:\")\n",
    "print(f\"  MSE: {mse_update:.3f}, MAE: {mae_update:.3f}, R2: {r2_update:.4f}\")\n",
    "\n",
    "# mcbart_update.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior sample shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def uniform_schedule(i): \n",
    "    return 1.0/mcbart_update._trace_length\n",
    "posterior_sample = mcbart_update.posterior_sample(X_test, schedule=uniform_schedule)\n",
    "print(f\"Posterior sample shape: {posterior_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray has been shut down.\n"
     ]
    }
   ],
   "source": [
    "mcbart_update.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 1200/1200 [00:14<00:00, 83.25it/s] \n",
      "Iterations: 100%|██████████| 1200/1200 [00:14<00:00, 83.25it/s] \n",
      "100%|██████████| 630/630 [00:31<00:00, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART sequential update_fit results:\n",
      "  MSE: 1.968, MAE: 1.128, R2: 0.9170\n",
      "Time taken for sequential updates: 45.98 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compare with sequential update_fit\n",
    "from tqdm import tqdm\n",
    "\n",
    "bart_seq = DefaultBART(random_state=RANDOM_STATE, \n",
    "                               n_trees=N_TREES, ndpost=NDPOST, nskip=NSKIP)\n",
    "start_time_seq = time.time()\n",
    "bart_seq.fit(X_initial, y_initial, quietly=False)\n",
    "for i in tqdm(range(len(X_update))):\n",
    "    bart_seq.update_fit(X_update[i:i+1], y_update[i:i+1], add_ndpost=5, quietly=True)\n",
    "end_time_seq = time.time()\n",
    "y_pred_seq = bart_seq.predict(X_test)\n",
    "mse_seq = mean_squared_error(y_test, y_pred_seq)\n",
    "mae_seq = mean_absolute_error(y_test, y_pred_seq)\n",
    "r2_seq = r2_score(y_test, y_pred_seq)\n",
    "print(f\"BART sequential update_fit results:\")\n",
    "print(f\"  MSE: {mse_seq:.3f}, MAE: {mae_seq:.3f}, R2: {r2_seq:.4f}\")\n",
    "print(f\"Time taken for sequential updates: {end_time_seq - start_time_seq:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Logistic MCBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING MCBART WITH LOGISTICBART\n",
      "============================================================\n",
      "\n",
      "=== Testing on Binary Classification ====\n",
      "Dataset shape: X=(1000, 10), y=(1000,)\n",
      "Classes: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 16:31:34,426\tINFO worker.py:1908 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 BARTActor(s) using BART class: LogisticBART\n",
      "  Training LogisticRegression...\n",
      "    Accuracy: 0.6600, Time: 0.06s\n",
      "  Training RandomForest...\n",
      "    Accuracy: 0.8267, Time: 0.08s\n",
      "  Training XGBClassifier...\n",
      "    Accuracy: 0.8900, Time: 0.76s\n",
      "  Training LogisticBART...\n",
      "    Accuracy: 0.8300, Time: 14.25s\n",
      "  Training MCLogisticBART...\n",
      "    Accuracy: 0.8267, Time: 7.39s\n",
      "Ray has been shut down.\n",
      "\n",
      "=== Testing on Multiclass Classification ====\n",
      "Dataset shape: X=(1000, 10), y=(1000,)\n",
      "Classes: [0 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 16:32:01,497\tINFO worker.py:1908 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 BARTActor(s) using BART class: LogisticBART\n",
      "  Training LogisticRegression...\n",
      "    Accuracy: 0.7267, Time: 0.16s\n",
      "  Training RandomForest...\n",
      "    Accuracy: 0.8767, Time: 0.11s\n",
      "  Training XGBClassifier...\n",
      "    Accuracy: 0.8867, Time: 0.05s\n",
      "  Training LogisticBART...\n",
      "    Accuracy: 0.8467, Time: 11.67s\n",
      "  Training MCLogisticBART...\n",
      "    Accuracy: 0.8033, Time: 7.88s\n",
      "Ray has been shut down.\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION SUMMARY RESULTS\n",
      "============================================================\n",
      "\n",
      "Accuracy:\n",
      "Model       LogisticBART  LogisticRegression  MCLogisticBART  RandomForest  \\\n",
      "Dataset                                                                      \n",
      "Binary            0.8300              0.6600          0.8267        0.8267   \n",
      "Multiclass        0.8467              0.7267          0.8033        0.8767   \n",
      "\n",
      "Model       XGBClassifier  \n",
      "Dataset                    \n",
      "Binary             0.8900  \n",
      "Multiclass         0.8867  \n",
      "\n",
      "Time (seconds):\n",
      "Model       LogisticBART  LogisticRegression  MCLogisticBART  RandomForest  \\\n",
      "Dataset                                                                      \n",
      "Binary             14.25                0.06            7.39          0.08   \n",
      "Multiclass         11.67                0.16            7.88          0.11   \n",
      "\n",
      "Model       XGBClassifier  \n",
      "Dataset                    \n",
      "Binary               0.76  \n",
      "Multiclass           0.05  \n",
      "\n",
      "============================================================\n",
      "TESTING LOGISTIC MCBART UPDATE_FIT\n",
      "============================================================\n",
      "Initial training size: 70\n",
      "Update size: 280\n",
      "Test size: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 16:32:25,487\tINFO worker.py:1908 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2 BARTActor(s) using BART class: LogisticBART\n",
      "\n",
      "Update Results:\n",
      "Initial accuracy: 0.7867\n",
      "Final accuracy: 0.8333\n",
      "Accuracy improvement: 0.0467\n",
      "Total update time: 8.53 seconds\n",
      "\n",
      "Testing posterior sampling...\n",
      "Posterior probability sample shape: (5, 2)\n",
      "Posterior f(x) shape: (5, 10, 2)\n",
      "Ray has been shut down.\n"
     ]
    }
   ],
   "source": [
    "# By Copilot\n",
    "\n",
    "# Test MCBART with LogisticBART for classification\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from bart_playground.bart import LogisticBART\n",
    "from bart_playground.mcbart import MultiChainBART\n",
    "import time\n",
    "\n",
    "def load_classification_datasets():\n",
    "    \"\"\"Load classification datasets for testing\"\"\"\n",
    "    # Simple binary classification\n",
    "    X_binary, y_binary = make_classification(\n",
    "        n_samples=1000, n_features=10, n_informative=8, n_redundant=2,\n",
    "        n_classes=2, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # Multiclass classification\n",
    "    X_multi, y_multi = make_classification(\n",
    "        n_samples=1000, n_features=10, n_informative=8, n_redundant=2,\n",
    "        n_classes=3, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"Binary\": (X_binary, y_binary),\n",
    "        \"Multiclass\": (X_multi, y_multi)\n",
    "    }\n",
    "\n",
    "def evaluate_classification_model(model, model_name, X_train, X_test, y_train, y_test, dataset_name):\n",
    "    \"\"\"Evaluate a classification model and return metrics\"\"\"\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, quietly=True)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get probabilities if available\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        y_proba = None\n",
    "    \n",
    "    time_end = time.time()\n",
    "    y_pred = y_pred.astype(int)\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Time': time_end - time_start,\n",
    "        'y_pred': y_pred,\n",
    "        'y_proba': y_proba\n",
    "    }\n",
    "\n",
    "def test_logistic_mcbart():\n",
    "    \"\"\"Test MultiChainBART with LogisticBART for classification\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING MCBART WITH LOGISTICBART\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load classification datasets\n",
    "    datasets = load_classification_datasets()\n",
    "    classification_results = []\n",
    "    \n",
    "    for dataset_name, (X, y) in datasets.items():\n",
    "        print(f\"\\n=== Testing on {dataset_name} Classification ====\")\n",
    "        print(f\"Dataset shape: X={X.shape}, y={y.shape}\")\n",
    "        print(f\"Classes: {np.unique(y)}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Define models for comparison\n",
    "        n_trees_logistic = 25  # LogisticBART typically uses fewer trees\n",
    "        ndpost_logistic = 500\n",
    "        nskip_logistic = 100\n",
    "        \n",
    "        models = {\n",
    "            \"LogisticRegression\": LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "            \"RandomForest\": RandomForestClassifier(n_estimators=n_trees_logistic, random_state=RANDOM_STATE),\n",
    "            \"XGBClassifier\": XGBClassifier(n_estimators=n_trees_logistic, random_state=RANDOM_STATE),\n",
    "            \"LogisticBART\": LogisticBART(\n",
    "                n_trees=n_trees_logistic, \n",
    "                ndpost=ndpost_logistic, \n",
    "                nskip=nskip_logistic, \n",
    "                random_state=RANDOM_STATE\n",
    "            ),\n",
    "            \"MCLogisticBART\": MultiChainBART(\n",
    "                n_ensembles=3,\n",
    "                bart_class=LogisticBART,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_trees=n_trees_logistic,\n",
    "                ndpost=ndpost_logistic//2,\n",
    "                nskip=nskip_logistic//2\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            print(f\"  Training {model_name}...\")\n",
    "            \n",
    "            if model_name in [\"LogisticBART\", \"MCLogisticBART\"]:\n",
    "                metrics = evaluate_classification_model(\n",
    "                    model, model_name, X_train, X_test, y_train, y_test, dataset_name\n",
    "                )\n",
    "            else:\n",
    "                # Standard sklearn models\n",
    "                time_start = time.time()\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None\n",
    "                time_end = time.time()\n",
    "                \n",
    "                metrics = {\n",
    "                    'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                    'Time': time_end - time_start,\n",
    "                    'y_pred': y_pred,\n",
    "                    'y_proba': y_proba\n",
    "                }\n",
    "            \n",
    "            result = {\n",
    "                'Dataset': dataset_name, \n",
    "                'Model': model_name, \n",
    "                'Accuracy': metrics['Accuracy'],\n",
    "                'Time': metrics['Time']\n",
    "            }\n",
    "            classification_results.append(result)\n",
    "            \n",
    "            print(f\"    Accuracy: {metrics['Accuracy']:.4f}, Time: {metrics['Time']:.2f}s\")\n",
    "        \n",
    "            # Shutdown MultiChainBART if needed\n",
    "            if model_name == \"MCLogisticBART\" and hasattr(model, 'shutdown'):\n",
    "                model.shutdown()\n",
    "    \n",
    "    # Display results\n",
    "    results_df = pd.DataFrame(classification_results)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CLASSIFICATION SUMMARY RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    pivot = results_df.pivot_table(index='Dataset', columns='Model', values='Accuracy')\n",
    "    print(\"\\nAccuracy:\")\n",
    "    print(pivot.round(4))\n",
    "    \n",
    "    pivot_time = results_df.pivot_table(index='Dataset', columns='Model', values='Time')\n",
    "    print(\"\\nTime (seconds):\")\n",
    "    print(pivot_time.round(2))\n",
    "\n",
    "def test_logistic_mcbart_update_fit():\n",
    "    \"\"\"Test LogisticBART update_fit functionality\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING LOGISTIC MCBART UPDATE_FIT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Use binary classification dataset\n",
    "    X, y = make_classification(\n",
    "        n_samples=500, n_features=8, n_informative=6, n_redundant=2,\n",
    "        n_classes=2, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Initialize with small subset\n",
    "    initial_size = int(0.2 * len(X_train))\n",
    "    X_initial = X_train[:initial_size]\n",
    "    y_initial = y_train[:initial_size]\n",
    "    X_update = X_train[initial_size:]\n",
    "    y_update = y_train[initial_size:]\n",
    "    \n",
    "    print(f\"Initial training size: {len(X_initial)}\")\n",
    "    print(f\"Update size: {len(X_update)}\")\n",
    "    print(f\"Test size: {len(X_test)}\")\n",
    "    \n",
    "    # Test MultiChain LogisticBART update\n",
    "    start_time = time.time()\n",
    "    \n",
    "    mcbart_logistic = MultiChainBART(\n",
    "        n_ensembles=2, \n",
    "        bart_class=LogisticBART,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_trees=15,\n",
    "        ndpost=200,\n",
    "        nskip=50\n",
    "    )\n",
    "    \n",
    "    # Initial fit\n",
    "    mcbart_logistic.fit(X_initial, y_initial, quietly=True)\n",
    "    initial_accuracy = accuracy_score(y_test, mcbart_logistic.predict(X_test).astype(int))\n",
    "    \n",
    "    # Update in batches\n",
    "    batch_size = 10\n",
    "    update_accuracies = []\n",
    "    \n",
    "    for i in range(0, len(X_update), batch_size):\n",
    "        end_idx = min(i + batch_size, len(X_update))\n",
    "        X_batch = X_update[i:end_idx]\n",
    "        y_batch = y_update[i:end_idx]\n",
    "        \n",
    "        mcbart_logistic.update_fit(X_batch, y_batch, add_ndpost=5, quietly=True)\n",
    "        \n",
    "        # Evaluate after update\n",
    "        y_pred = mcbart_logistic.predict(X_test).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        update_accuracies.append(accuracy)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"\\nUpdate Results:\")\n",
    "    print(f\"Initial accuracy: {initial_accuracy:.4f}\")\n",
    "    print(f\"Final accuracy: {update_accuracies[-1]:.4f}\")\n",
    "    print(f\"Accuracy improvement: {update_accuracies[-1] - initial_accuracy:.4f}\")\n",
    "    print(f\"Total update time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Test posterior sampling\n",
    "    print(f\"\\nTesting posterior sampling...\")\n",
    "    \n",
    "    def uniform_schedule(i):\n",
    "        return 1.0 / mcbart_logistic._trace_length\n",
    "    \n",
    "    # Get posterior samples (probabilities)\n",
    "    posterior_proba_sample = mcbart_logistic.posterior_sample(X_test[:5], schedule=uniform_schedule)\n",
    "    print(f\"Posterior probability sample shape: {posterior_proba_sample.shape}\")\n",
    "    \n",
    "    # Test posterior prediction probabilities\n",
    "    posterior_proba = mcbart_logistic.posterior_f(X_test[:5])\n",
    "    print(f\"Posterior f(x) shape: {posterior_proba.shape}\")\n",
    "    \n",
    "    mcbart_logistic.shutdown()\n",
    "\n",
    "# Run the tests\n",
    "test_logistic_mcbart()\n",
    "test_logistic_mcbart_update_fit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "bartpg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
